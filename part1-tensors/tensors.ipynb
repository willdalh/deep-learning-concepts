{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    import torch\n",
    "    from IPython.core.display import HTML\n",
    "    from IPython.display import display\n",
    "    import os\n",
    "    print(\"Running in Google Colab\")\n",
    "    if not torch.cuda.is_available():\n",
    "        display(HTML(\"\"\"<div style=\"background-color: red; font-weight: bold; color: white;\">You have not activated a GPU in Google Colab. Follow the instructions in the <code style=\"color: white;\">README</code></div>\"\"\"))\n",
    "    print(\"Installing requirements\")\n",
    "    requirements_url = \"https://raw.githubusercontent.com/willdalh/ml-course/main/requirements.txt\"\n",
    "    if not os.path.exists('requirements.txt'):\n",
    "        !wget {requirements_url}\n",
    "    %pip install --user -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch\n",
    "\n",
    "PyTorch er et av flere biblioteker som brukes til trening av dype nevrale nettverk. Et annet kjent alternativ, er TensorFlow. Hva man velger avhenger av hva man er vant med, men begge har sine fordeler og ulemper. I noen tilfeller er PyTorch foretrukket fordi det er mer tydelig hvordan treningsprosessen av nevrale nettverk foregår. PyTorch er også mer brukt i akademia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vektorer og matriser - generalisert som tensorer\n",
    "Fra matematikken vet vi at en liste med feks. 3 tall definerer en vektor/punkt som lever i et tre-dimensjonalt rom. I PyTorch representeres dette gjennom datatypen `Tensor`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 2., 1.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [3, 2, 1] # Normal python list\n",
    "vector = torch.Tensor(data) # Creating a tensor from it\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Med tensorer er det flere operasjoner som kan gjøres (som vi også til en grad kan forvente av native Python-lister)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value: 3.0\n",
      "Min value: 1.0\n",
      "Index of max element: 0\n",
      "Index of min element: 2\n",
      "Sum: 6.0\n",
      "Sorted:  tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max value: {vector.max()}\")\n",
    "print(f\"Min value: {vector.min()}\")\n",
    "\n",
    "print(f\"Index of max element: {vector.argmax()}\")\n",
    "print(f\"Index of min element: {vector.argmin()}\")\n",
    "\n",
    "print(f\"Sum: {vector.sum()}\")\n",
    "\n",
    "print(f\"Sorted:  {torch.sort(vector).values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kan lage et punkt som lever i flere dimensjoner, for eksempel 16 (som vi heller lager med tilfeldige tall):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 5, 3, 5, 4, 5, 5, 9, 2, 6, 9, 5, 3, 1, 2, 2])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_dim_vector = torch.randint(low=1, high=10, size=(16,))\n",
    "high_dim_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En matrise er en rektangulær liste / tabell. Det er her `torch.Tensor` begynner å divergere fra vanlige Python-lister.  \n",
    "Vi lager en $2 \\times 3$-matrise, altså med 2 rader og 3 kolonner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 4, 8],\n",
       "        [8, 9, 8]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.randint(low=1, high=10, size=(2, 3))\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Størrelsen og formen på matrisen kaller vi for _shape_. Er vi usikker på hvilken shape matrisen har, kan vi sjekke det med `.shape` attributtet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the matrix is torch.Size([2, 3])\n",
      "It has 2 rows and 3 columns\n"
     ]
    }
   ],
   "source": [
    "print(f\"The shape of the matrix is {matrix.shape}\")\n",
    "rows, cols = matrix.shape\n",
    "print(f\"It has {rows} rows and {cols} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kan ta det et steg videre ved å legge til dybde på en matrise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the tensor is torch.Size([2, 3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[9, 6, 2, 0],\n",
       "         [6, 2, 7, 9],\n",
       "         [7, 3, 3, 4]],\n",
       "\n",
       "        [[3, 7, 0, 9],\n",
       "         [0, 9, 6, 9],\n",
       "         [5, 4, 8, 8]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.randint(low=0, high=10, size=(2, 3, 4))\n",
    "print(f\"The shape of the tensor is {tensor.shape}\")\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensoren over består av 2 matriser som hver har 3 rader og 4 kolonner. Disse kan vi hente ut med indeksering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix 1:\n",
      " tensor([[9, 6, 2, 0],\n",
      "        [6, 2, 7, 9],\n",
      "        [7, 3, 3, 4]])\n",
      "Matrix 2:\n",
      " tensor([[3, 7, 0, 9],\n",
      "        [0, 9, 6, 9],\n",
      "        [5, 4, 8, 8]])\n"
     ]
    }
   ],
   "source": [
    "matrix_1 = tensor[0]\n",
    "matrix_2 = tensor[1]\n",
    "print(f\"Matrix 1:\\n {matrix_1}\")\n",
    "print(f\"Matrix 2:\\n {matrix_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I praksis brukes ordene _vektor_ og _tensor_ om hverandre. Begge beskriver en samling verdier strukturert med en vilkårlig _shape_. I bunn og grunn er de flerdimensjonale lister/arrays. \n",
    "\n",
    "Hva man legger i begrepet _dimensjoner_ når man refererer til en tensor, er todelt:\n",
    "- Antall elementer til sammen i tensoren (riktig matematisk sett)\n",
    "- Antall elementer som ligger i `.shape`-attributtet \n",
    "\n",
    "For å minske forvirringen kaller man ofte den første for antall _features_. Den andre kan vi kalle for shape-dimensjoner. \n",
    "\n",
    "Da gjelder følgende for tensoren vår:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensor has 24 features\n",
      "The tensor has 3 shape dimensions\n"
     ]
    }
   ],
   "source": [
    "num_features = tensor.numel()\n",
    "print(f\"The tensor has {num_features} features\")\n",
    "num_shape_dims = tensor.dim()\n",
    "print(f\"The tensor has {num_shape_dims} shape dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funksjonalitet utover det man finner i vanlige Python-lister  \n",
    "Tensorer er veldig fleksible. Vi kan for eksempel slå sammen radene og kolonnene ved å utføre en `reshape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([2, 3, 4])\n",
      "Shape of the reshaped tensor: torch.Size([2, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[6, 0, 0, 0, 0, 1, 3, 0, 1, 1, 7, 9],\n",
       "        [4, 3, 8, 9, 3, 7, 8, 1, 4, 1, 6, 3]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.randint(low=0, high=10, size=(2, 3, 4))\n",
    "print(f\"Original shape: {tensor.shape}\")\n",
    "reshaped = tensor.reshape(2, 3*4) # Combine the rows and columns into one\n",
    "print(f\"Shape of the reshaped tensor: {reshaped.shape}\")\n",
    "reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hvis det er en shape-dimensjon vi ikke har styr på og ofte varierer kan vi la PyTorch regne den ut selv ved å spesifisere `-1` for **en** av posisjonene.\n",
    "\n",
    "Dette er veldig nyttig når vi ønsker å samle flere datapunkt i en tensor. Vi vet gjerne hvordan et datapunkt ser ut, feks vil et bilde ha en bestemt oppløsning og antall fargekanaler. Disse verdiene vil være felles for alle datapunkt i datasettet. Denne prosessen kalles for batching, og vi kommer tilbake til det senere. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 0, 0, 0, 0, 1, 3, 0, 1, 1, 7, 9],\n",
      "        [4, 3, 8, 9, 3, 7, 8, 1, 4, 1, 6, 3]])\n",
      "PyTorch infers the first shape dimension to be 2\n"
     ]
    }
   ],
   "source": [
    "reshaped = tensor.reshape(-1, 3*4)\n",
    "print(reshaped)\n",
    "print(f\"PyTorch infers the first shape dimension to be {reshaped.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Når vi har flere _shape_-dimensjoner har vi muligheten til å spesifisere dimensjoner av interesse for noen av operasjonene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 7, 6],\n",
       "        [4, 6, 5]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "tensor = torch.randint(low=0, high=10, size=(2, 3))\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summing across rows: tensor([ 6, 13, 11])\n",
      "Summing across columns: tensor([15, 15])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Summing across rows: {tensor.sum(dim=0)}\")\n",
    "print(f\"Summing across columns: {tensor.sum(dim=1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min values across rows: tensor([2, 6, 5])\n",
      "Min values across columns: tensor([2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Min values across rows: {tensor.min(dim=0).values}\")\n",
    "print(f\"Min values across columns: {tensor.min(dim=1).values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Legge til og fjerne tomme dimensjoner\n",
    "Antall shape-dimensjoner i to tensorer kan være forskjellige, mens dataene tilsynelatende har en lik struktur. \n",
    "For å illustrere dette starter vi med en vektor som inneholder 4 features. Denne legger vi til en _tom_ shape-dimensjon på med `.unsqueeze(dim=X)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor is tensor([0, 4, 0, 3]) with shape torch.Size([4])\n",
      "Modified tensor is tensor([[0, 4, 0, 3]]) with shape torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randint(low=0, high=10, size=(4,))\n",
    "print(f\"Original tensor is {tensor} with shape {tensor.shape}\")\n",
    "modified = tensor.unsqueeze(0)\n",
    "print(f\"Modified tensor is {modified} with shape {modified.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kan også fjerne tomme dimensjoner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8],\n",
       "        [4],\n",
       "        [0],\n",
       "        [4]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.randint(low=0, high=10, size=(4, 1)) # 4 rows and 1 column\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 4, 0, 4])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified = tensor.squeeze(1)\n",
    "modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch er litt streng, og vi kommer til å oppleve at den setter krav til hvilken shape tensorene våre skal ha når vi bruker hjelpemetodene i biblioteket. Nevrale nettverk som vi bygger med PyTorch (mer om det i neste del) forventer at input-dataen kommer som flere datapunkt samlet. Hvis vi bare skal sende inn et datapunkt må vi dytte inn en tom batch-dimensjon framst i tensoren. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flytting av tensorer mellom enheter\n",
    "Vi skriver PyTorch-kode gjennom Python, men mye av beregningene foregår i et C++ backend. Dette er nødvendig for at ressurskrevende operasjoner kan gjøres på grafikkort. Det eneste vi trenger å gjøre er å flytte tensorer dit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default tensor location: cpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"Default tensor location: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"GPU is available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CUDA](https://en.wikipedia.org/wiki/CUDA) er API-et som brukes for å kjøre beregninger på NVIDIA-grafikkort. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor location: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = tensor.to(device)\n",
    "print(f\"Tensor location: {tensor.device}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

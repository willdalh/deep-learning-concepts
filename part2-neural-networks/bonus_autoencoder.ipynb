{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder\n",
    "\n",
    "AutoEncoders er TODO\n",
    "\n",
    "<img src=\"../res/autoencoder.png\" height=\"300px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Pipeline of processing operations\n",
    "image_processing = transforms.Compose([\n",
    "    transforms.ToTensor(), # Cast into torch.Tensor\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Pixel-values will range in [-1, 1]\n",
    "])\n",
    "\n",
    "train_dataset = MNIST(root='../data', train=True, transform=image_processing, download=True)\n",
    "test_dataset = MNIST(root='../data', train=False, transform=image_processing, download=True) # Test data for later\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32) # Iterable that provides 16 data samples each iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En AutoEncoder består av to komponenter:\n",
    "- Encoder\n",
    "    - En sekvens med lineære lag som reduserer dimensjonaliteten.\n",
    "    - Ender opp med en vektor med veldig få dimensjoner kontra 784 fra rådata.\n",
    "- Decoder\n",
    "    - En sekvens med lineære lag som rekonstruerer inputten fra den korte vektoren.\n",
    "\n",
    "Vi tar i bruk `nn.Sequential` for å lage sekvenser av lag som dataen flyter gjennom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=200, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=200, out_features=42, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=42, out_features=16, bias=True)\n",
       "    (5): Tanh()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=42, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=42, out_features=200, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=200, out_features=784, bias=True)\n",
       "    (5): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28, out_features=200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=200, out_features=42),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=42, out_features=16),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "             nn.Linear(in_features=16, out_features=42),\n",
    "             nn.Tanh(),\n",
    "             nn.Linear(in_features=42, out_features=200),\n",
    "             nn.Tanh(),\n",
    "             nn.Linear(200, 28*28),\n",
    "             nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def encode(self, data):\n",
    "        out = torch.flatten(data, start_dim=1, end_dim=-1)\n",
    "        out = self.encoder(out)\n",
    "        return out\n",
    "    \n",
    "    def decode(self, data):\n",
    "        out = self.decoder(data)\n",
    "        return out.reshape(-1, 1, 28, 28)\n",
    "\n",
    "    def forward(self, data):\n",
    "        out = self.encode(data)\n",
    "        out = self.decode(out)\n",
    "        return out\n",
    "    \n",
    "autoencoder = AutoEncoder()\n",
    "autoencoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1875/1875 [00:09<00:00, 206.88batch/s, loss=0.123]\n",
      "Epoch 1: 100%|██████████| 1875/1875 [00:07<00:00, 243.48batch/s, loss=0.0916]\n",
      "Epoch 2: 100%|██████████| 1875/1875 [00:07<00:00, 253.43batch/s, loss=0.0684]\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    with tqdm(train_loader, unit=\"batch\") as pbar:\n",
    "        pbar.set_description(f\"Epoch {epoch}\")\n",
    "        for i, (data, _) in enumerate(pbar): # no need for labels\n",
    "            data = data.to(device)\n",
    "            pred = autoencoder.forward(data) # Query model for predictions\n",
    "            loss = loss_fn(pred, data)\n",
    "            \n",
    "            loss.backward() # Propagate the computational graph and calculate gradients\n",
    "            optimizer.step() # Uses the calculated gradients on the registered parameters to perform an update\n",
    "            optimizer.zero_grad() # Remove the gradients\n",
    "\n",
    "            pbar.set_postfix(loss=loss.cpu().item()) if i%40 == 0 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi studerer nå hvordan modellen klarer å rekonstruere et siffer fra datasettet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKgAAACoCAAAAABRIPpoAAADfklEQVR4Ae2avWsUQRiHTyPiF0a0iIJGSz9ABSF/gogIucYopBARFKxs7GwEIVhFISBIGkEF8auwUFAsBC1Fo2hSxk6iGA40iYoKz9vMZndh9t5BHPlZPPvO3Ozs3PPemx1vr9XSPxmQARmQARmQARmQARmQARmQARmQARmQARmQgTwMLPmby1zPxYbgRfgd7oQzsA5L61741/q10NQZkdHURhNU/SHW9Ax2gvX1EI/BXngkeDUMJ2kMwK/hC0Gs1AcykoQymkRjMEk2RpcFi+4y3Md5w/AYtDv4eeK90Cr6M/FtOAVH4XY4CG/CMrIxqoWWk+frkVGfv/LZCareatz27Su5wgd4Eh6A8/At7IePoGGSw72gpxwq9WUnvh4Z9fkrn52N0QQ7/FW8/edwN7wA78IJaLB9vo3cQddruB9+skE1zMaoFlqTwa67ZbRrdTUnJqh6m9lq/x2NdXAPnIZr4DXYhoajHGzPH3RXhEp9hRRXl4y69FWcnI3RBDt8e/vfOMzCLfA0fAEvB/1zxOfgfRiDbIxqoTHpbDJGRpvYihmb7F5vFzvM4QZcgPY8biux1ftZ4iswHkp9vKu4kTIa5yl+VDZGE1e9bR06iFoBf0P7C2BP7h7EawxGZmNUCw2yliSU0SQag0mS7fBtzp8crNKt5weHM7C7erd5lHrzkI4yms5lZp/RZFVvn6EJ3r49v7NtxFN6rroF6zPqVrhoAhldJMTdzMZogqpfi61RaM/jwnt9zPfzMbqzMaqFxqSzyRgZbWIrZqyr6jdzhZdwQ3C1eWK74/cE/Z5QqffYqzpXRqusePqyMdpl1fci5w4M632Enj54As5CP7IxqoX6k12cQUaLPvytxlXf5ppjcBOcg6fgQ2i7fftmb5oeP5R6v8PiDDJa9OFvZWO0wZO7NlquQ9u92y/xhuh5D/vhFPwFV0M/sjGqhfqTXZxBRos+/K2oe/0A17kErd6txm0Pb/FBXh2By+Fj2Ac/Qg+Ueo+9qnNltMqKpy8bo1FVfxwV9jtbs2Lf4LVp2C/xthHb+54hHoQL0I9sjGqh/mQXZ5DRog9/K6rqN5auMxz0fCF+Bcdh+ItcOhJAqU8gsTCFjBZ0JGhkYzSq6q2W7f/pu7DzBj6Bt2AH2hjCxMjGqBaaOPMtGU1tVPPJgAzIgAzIgAzIgAzIgAz8Twb+AGnSXGHFgG2TAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=168x168>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from utils.visualize import visualize\n",
    "\n",
    "\n",
    "rand_index = torch.randint(0, len(train_dataset), (1,)).item()\n",
    "data_sample, label_sample = train_dataset[rand_index]\n",
    "\n",
    "visualize(data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16])\n",
      "tensor([[-0.3993, -0.3601,  0.4742, -0.3874,  0.6344, -0.0570, -0.1138, -0.4713,\n",
      "          0.4179, -0.3142,  0.6381,  0.2136,  0.2608, -0.6189,  0.4074,  0.3008]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAGAGABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/AOMX7wrufh//AMxH/tl/7NWF4v8A+RovP+Af+gLXqPib/kXrr/gH/oYrzmXtXM6n/wAhGX8P5CvT/FH/ACLt1/wD/wBDWq3w2/5if/bL/wBnrU1f/kKTf8B/9BFc34w/5Fa9/wCAf+hrWZ8MP+Yr/wBsf/Z67ib/AFrV/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGAAAAAGCAAAAAAZXsSjAAAAQUlEQVR4AWP0YQABVjCZBSYng8kmMLkCTP4Ak5fBZCGYXAwmK8HkKTDJBiYngMlmMPkJTDKBSRoSoxYQDFyaBxEABQUIsS09oP4AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=96x6>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = autoencoder.encode(data_sample[None, ...].to(device)) # Add batch dimension\n",
    "encoding\n",
    "print(encoding.shape)\n",
    "print(encoding)\n",
    "visualize(encoding[None, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3993, -0.3601,  0.4742, -0.3874,  0.6344, -0.0570, -0.1138, -0.4713,\n",
       "          0.4179, -0.3142,  0.6381,  0.2136,  0.2608, -0.6189,  0.4074,  0.3008]],\n",
       "       device='cuda:0', grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKgAAACoCAAAAABRIPpoAAAEdklEQVR4Ae2ay2sUQRCHo2t8xojG+AzRGNT4QgUFBRU8iiAKnr178+Rf4UXBi3+BJwkEPAhGDx6EePNBRGIU8YGJeaxGY2Ki8P089JIZkpmuBVsqhy+1NdM13b+a2uoZtqHB/1wBV8AVcAVcAVfAFXAFXAFXwBVwBVwBVyBVBRbVe+K6wFIusyrgYuxh+AtOQeF3YMvU+XPc/57DJ2qdE1fUWlGzqldqKsH8lmG3w9PwEDwAv8A+2AM/wCE4A8Pa99QjiSFcUUMxCZWMoktiVq5VNhJCfVyV3obnCDwI98GNcAXshFthC7wNv8IJGCIZRX2iYdosbFfUQsUwRuGq1+ZArBCpGaqKd2GfCTy6wAieSahvBqWyFc9R+AQOwB9QHR+zwVMvHezoitppmdg9WrjqtetW1avLb2fJF6FsBX2Ppx/qDtM3w148K6HijGG/gur14VVk+z2KPIZwRQ3FJFQyihau+lAp7epVxarfWQ4/g4NQz+9V7AtQ+/z12N/hSxj2d1W6yEHv9ZLBkMncoz5Rw6wTqmTVqx4nCPECboHavatfv8azGh6BHVD79k/Y9+Ed+BnqfX5Y77i96iWDIb2YDMUkVDKKRlW9Oru6+VvWrQ6+HVv1rvd4XXiqUHV9D/sWHILjUDExa5CMoj7RmrwZfHBFDUSsCVGy6hVD9auOrzfz7RxYDlXv8uhZ4Cf+m7AHauw09tz+jvsvPPWhGha2K2qhYhgjGUWjql579VEWrr36YewTsAk2wzF4A3bD8K0djnmQjKI+0XkyWfiwK1pYsnkGRFW9urM69QgXUu9eg60d/iD2VfgIquNjFoCnvoBYCzrVFV2QTAVOSkbRqKqXIBX+7Qmo/fxrPNdhHyxX7wz1t3mSwZDJ3KM+UcOsE6pk1SsRqu4rBDoPW+AY7IWPofYAmCXhqS8pXO4wVzRXmpIHklG0cNVrZZ3ooj5+DFu7/Sr2MHwOiz6/MygDySjqE83IXpTLFY2SL2Pwgqp+KQP1Zn4n9mUoexR7DH6CerevX+CI+k7gYEl46ksKlzvMFc2VpuSBZBSdp+obWf9+2AHPwjbYD/Ue7yO29gAatRmPvismsGOQjKI+0Zg0Z411RbNUifFlVP0i4klq/eLuJJ5zsBVW4VP4Fh6HG6A6uzq+Vcqs4jDBesInaq2uK2qtaG7Va1e/luup1+/GboZ6Wp/E7oLq/uryD/E8gOMwHp76eA1rI7iitXrEf0pG0Yyqn2X5FViF22AT1I5dw1Tv8qi/v+Ec/WLnHfY0jEcyivpE45NdG8EVrdUj/lNG1Suo3sLpefwurh1wE9Swddjf4AC8BvUb+0lsfYdgRsFTHyVfxmBXNEOUKFcyiuohPmOt4Qr0LH+Ksy7BjXAU9sJuOAjV39X9cRggnI9BuPqF8Ilaa+uKWiuaW/XhhSS7TtXzfjhsilNnoG2lz51D6PlHbb9HrRPjilorGpZvbmydJGrHHnpU6fWrd03LU5+bnpIHXNGSwuUOS0bR3BX4AVfAFfhPFfgDWeKWAJILDX8AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=168x168>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoding = autoencoder.decode(encoding)\n",
    "visualize(decoding.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ved å ha en flaskehals i midten av nettverket, har modellen lært seg en lav-dimensjonell representasjon av sifrene.\n",
    "\n",
    "Det morsomme er at decoder-delen av nettverket kan anvendes som en generativ modell. Inputtet vil være en vektor av lav dimensjon. Vi har også brukt `Tanh` som aktiveringsfunksjon på output fra encoderen, som betyr at decoderen alltid vil forvente tall som ligger i $\\langle-1, 1\\rangle$. \n",
    "\n",
    "Hvis vi generer en 16-dimensjonal vektor med tilfeldige tall, og bruker dette som input til decoderen, får vi et _syntetisk_ siffer som output. Den 16-dimensjonale vektoren vil i faglitteraturen kalles for en _latent_ representasjon av et siffer.\n",
    "\n",
    "Jeg skrev [masteroppgaven min](https://willdalh.github.io/thesis/thesis.pdf) om latente representasjoner i diffusjonsmodeller. Bare ta en titt 😄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKgAAACoCAAAAABRIPpoAAAE0UlEQVR4Ae2bzatVVRjGj3q7mpmiRdiHeAUDIcWJRkSC0sSho2jWIBxEQYP+BP8LcebEBhEOHTRwKhJWAym1LBC1/KhrH36lwe+n8G722ffss8+C7oLXwXPf/a53vXutZ51nv2vtcxyN8l8ykAwkA8lAMpAMJAPJQDKQDCQDyUAykAzUysCK/3fg3n5lGMQj7MfBoxljWo3LyZEDLb0ayWhpRguofhVjmgc3h/Gp3EU8d0Fvtgb7AbgeVOkPsY28gx21n0sPJQUhGS1IJqmqYXRu2MzV+Jt0PghuD/PehX0DvAh+B/4J/gZeAv8FN4F/gbdBIzFHar8aRnOgLls5TEbLcWmmKVRvpV5Lv3fBT8HdoH7TGbkV/0uglf009k1wI6jqrf7iP/jN4B4AxyiXXh7KYTJajsvKPqNz6st62oeFbQR9Au4F1Xvsq5at1/doeAZcDbqr34n9A6jSL2FfAx0V5hPIz2hko4SdjJZgMeaohtG5/nq3jr/BNN8C1Xusy3fx/w5a069jPwT3gBdA9wA/Y/8IXgWt7z43zOwIq2E0B8o6FoRktCCZpFLKvbJaqY8Q29a77988s58h5jXwMrgBFN7mz2XwefA+qMY93eNoQC59g44CF8loARIbKaphtJfq1aNVfgvzdH5xn2DMA1p3hxj39i/gsYLrMfJb/D4r3CfgGAPVMJoDHbN6M7mS0ZnoG9O5l+rV6WG6xw4q3UWxar8ebqHGreNmWEWr6t6BfSzEewoIjoaZS9+go8BFMlqAxEaKahiNIm7MIF6o1q24VHps1ROfAO4B7KXe23w8R4p14CIY39jH/NrtDO2YZeHJgZZehmS0NKMTVB+1fId7W7s947efAO09f3wm2Ooi3iabb+/7LGufmNLkDMqXAx1E2xKdktElyBnUNEH16tRv305wg7XgHtA6bo2+hcf38NuwXwS9gXlitkVazeyuAEcn5NJ3UjOwIRkdSFxnt2oYnaB6J+gJ/RQX34Oeys9h/wF6Wt+CfRTcAMYb+Hz4Bf9XYJ/3eATmr3SkoSBW8xnNgRZcdVJFUY7JHffnvnVXsz8R+zfoM8F6vQmP2o+nAKu8p4OzxBwHr4cMmJ2QS99JzcCGZHQgcZ3dqmFUWXfOwwZ38hu5mAcXQVWv3hfwfAG6E4gc+GQ4R+v7oM+Npd/gEfgEYrboX3Z2DrT0kiSjpRlt1HofAdbleCO16a/pFmhYA3qKfw/7A3A92IYruD4Cp9W7o8qlb7M6mycZnY2/du9qGG2ovq13Z+ZsfN++D9c74KsBu97IeS74jMhvwP71nfD8P3fSUByr+YzmQEuvfUP1Xcl9GqjfzQQtgFb/Lr37q5uPiTwJ6sGcGnLpp6ZsQodkdAJBUzdXw2gv1Vudf4WFL8H9oH7nGk8HN2g9AJ4Hu3YRNPaCahjNgfZazymCktEpyOoVqlgbobqiim2e588r4IfgIdBa/zX25+Ap8B5YCnLpSzH5NE8y+pSJUn+rYXSM6uXAGVjNDVLdz9L8MrgOvAn6Zs/v5nAUhmoYzYEWXvn8qUZpQkedqm/fqa19v4/zvO+ZffadfPu+elJMXcwM9SejQ5nr6lcNoxNUb3Nby13+Lj5m91fDaA509sVuZkhGm3zkVTKQDCQD0zLwHwLio7tkrLOeAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=168x168>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent = (torch.rand(size=(1, 16))-0.5)*2\n",
    "decoding = autoencoder.decode(latent.to(device))\n",
    "visualize(decoding.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultatene gjenspeiler den enkle arkitekturen som er valgt. Det er flere forbedringer man kan gjøre på arkitekturen for å få mer lovende sifre. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO FIX Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Tanh()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Tanh()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    (7): Linear(in_features=1568, out_features=512, bias=True)\n",
       "    (8): Tanh()\n",
       "    (9): Linear(in_features=512, out_features=42, bias=True)\n",
       "    (10): Linear(in_features=42, out_features=16, bias=True)\n",
       "    (11): Tanh()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=42, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=42, out_features=512, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=512, out_features=1568, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Unflatten(dim=1, unflattened_size=(32, 7, 7))\n",
       "    (7): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (8): Tanh()\n",
       "    (9): ConvTranspose2d(16, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (10): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=32*7*7, out_features=512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=512, out_features=42),\n",
    "            nn.Linear(in_features=42, out_features=16),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=16, out_features=42),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=42, out_features=512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=512, out_features=32*7*7),\n",
    "            nn.Tanh(),\n",
    "            nn.Unflatten(1, (32, 7, 7)),\n",
    "            nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose2d(in_channels=16, out_channels=1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def encode(self, data):\n",
    "        # out = torch.flatten(data, start_dim=1, end_dim=-1)\n",
    "        out = self.encoder(data)\n",
    "        return out\n",
    "    \n",
    "    def decode(self, data):\n",
    "        out = self.decoder(data)\n",
    "        return out.reshape(-1, 1, 28, 28)\n",
    "\n",
    "    def forward(self, data):\n",
    "        out = self.encode(data)\n",
    "        out = self.decode(out)\n",
    "        return out\n",
    "    \n",
    "autoencoder = AutoEncoder()\n",
    "autoencoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    import torch\n",
    "    from IPython.core.display import HTML\n",
    "    from IPython.display import display\n",
    "    import os\n",
    "    print(\"Running in Google Colab\")\n",
    "    if not torch.cuda.is_available():\n",
    "        display(HTML(\"\"\"<div style=\"background-color: red; font-weight: bold; color: white;\">You have not activated a GPU in Google Colab. Follow the instructions in the <code style=\"color: white;\">README</code></div>\"\"\"))\n",
    "    print(\"Installing requirements\")\n",
    "    requirements_url = \"https://raw.githubusercontent.com/willdalh/ml-course/main/requirements.txt\"\n",
    "    if not os.path.exists('requirements.txt'):\n",
    "        !wget {requirements_url}\n",
    "    %pip install --user -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder\n",
    "\n",
    "AutoEncoder er en nettverksarkitektur som rekonstruerer input fra en lav-dimensjonell representasjon av input. Input er for eksempel pikslene på et bilde. Disse går gjennom en serie nettverkslag som reduserer antall features, frem til man når en flaskehals. Fra flaskehalsen skal modellen så gjenskape det som var i input. \n",
    "\n",
    "<img src=\"../res/autoencoder.png\" height=\"300px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En AutoEncoder består av to komponenter:\n",
    "- Encoder\n",
    "    - En sekvens med lineære lag som reduserer dimensjonaliteten.\n",
    "    - Ender opp med en vektor med veldig få dimensjoner kontra 784 fra rådata.\n",
    "- Decoder\n",
    "    - En sekvens med lineære lag som rekonstruerer inputten fra den korte vektoren.\n",
    "\n",
    "Vi tar i bruk `nn.Sequential` for å lage sekvenser av lag som dataen flyter gjennom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=200, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=200, out_features=42, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=42, out_features=64, bias=True)\n",
       "    (5): Tanh()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=42, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=42, out_features=200, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=200, out_features=784, bias=True)\n",
       "    (5): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, bottleneck_size=16):\n",
    "        super().__init__()\n",
    "        self.bottleneck_size = bottleneck_size\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28, out_features=200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=200, out_features=42),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=42, out_features=bottleneck_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "             nn.Linear(in_features=bottleneck_size, out_features=42),\n",
    "             nn.Tanh(),\n",
    "             nn.Linear(in_features=42, out_features=200),\n",
    "             nn.Tanh(),\n",
    "             nn.Linear(200, 28*28),\n",
    "             nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def encode(self, data):\n",
    "        out = torch.flatten(data, start_dim=1, end_dim=-1)\n",
    "        out = self.encoder(out)\n",
    "        return out\n",
    "    \n",
    "    def decode(self, data):\n",
    "        out = self.decoder(data)\n",
    "        return out.reshape(-1, 1, 28, 28)\n",
    "\n",
    "    def forward(self, data):\n",
    "        out = self.encode(data)\n",
    "        out = self.decode(out)\n",
    "        return out\n",
    "    \n",
    "autoencoder = AutoEncoder(bottleneck_size=64)\n",
    "autoencoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "# Pipeline of processing operations\n",
    "image_processing = transforms.Compose([\n",
    "    transforms.ToTensor(), # Cast into torch.Tensor\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Pixel-values will range in [-1, 1]\n",
    "])\n",
    "\n",
    "train_dataset = MNIST(root='../data', train=True, transform=image_processing, download=True)\n",
    "test_dataset = MNIST(root='../data', train=False, transform=image_processing, download=True) # Test data for later\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi trener modellen med _Mean-Squared Error_ som loss-funksjon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1875/1875 [00:12<00:00, 146.23batch/s]\n",
      "Epoch 1: 100%|██████████| 1875/1875 [00:15<00:00, 122.41batch/s]\n",
      "Epoch 2: 100%|██████████| 1875/1875 [00:12<00:00, 148.41batch/s]\n",
      "Epoch 3: 100%|██████████| 1875/1875 [00:12<00:00, 148.79batch/s]\n",
      "Epoch 4: 100%|██████████| 1875/1875 [00:12<00:00, 154.07batch/s]\n",
      "Epoch 5: 100%|██████████| 1875/1875 [00:13<00:00, 136.81batch/s]\n",
      "Epoch 6: 100%|██████████| 1875/1875 [00:12<00:00, 147.15batch/s]\n",
      "Epoch 7: 100%|██████████| 1875/1875 [00:11<00:00, 158.24batch/s]\n",
      "Epoch 8: 100%|██████████| 1875/1875 [00:13<00:00, 143.10batch/s]\n",
      "Epoch 9: 100%|██████████| 1875/1875 [00:13<00:00, 138.95batch/s]\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    with tqdm(train_loader, unit=\"batch\") as pbar:\n",
    "        pbar.set_description(f\"Epoch {epoch}\")\n",
    "        for i, (data, _) in enumerate(pbar): # no need for labels\n",
    "            data = data.to(device)\n",
    "            pred = autoencoder.forward(data) # Query model for predictions\n",
    "            loss = loss_fn(pred, data)\n",
    "            \n",
    "            loss.backward() # Propagate the computational graph and calculate gradients\n",
    "            optimizer.step() # Uses the calculated gradients on the registered parameters to perform an update\n",
    "            optimizer.zero_grad() # Remove the gradients\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi studerer nå hvordan modellen klarer å rekonstruere et siffer fra datasettet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKgAAACoCAAAAABRIPpoAAADAElEQVR4Ae2cPWuUQRSF108Q0V5EiZDKRhDBws7GTlEsRPQX2NtaWWmvIJaWokZRSws7Le3EYKGICBLQgOIHwhkhNww7e+7uu+rIk+Jk9t4zszPP3bu8ebPJaMQXBCAAAQhAAAIQgAAEIAABCEAAAhCAAAQgAAEIQAACEIAABCDw9wlsmG4LuzTtijQusV2RA9IF6VPpdekt6XSycbppf34WGx2aOUSHJhpbdsLaO5S/LT0i3TZhxlr6u4ZL0nPSL2tJa0TpLUwJE0QTsCxrN0Strt+qM9+Qng/nf63xR+l96ar0iXQh6GWNt0gvSq9KfemGKBv1i+o5Iepx8l2bHesemWK/v1PkoHRFWstzhU5KN4W0f4UQJo0ofaQxxBiiQ1CMa3RD1Or6eLJyrX5MoZWYGDM+o/jsPGZfYcwGhw6zUYgOTWDo9ayuXwzP+k3jFyEybliW3lelf1QRJ0AzOZQyHohmaDnebohaXX/YOXLluabIoRAvdwBuhog/7IYoG/WL6jkh6nHyXVbXl5/inUXLlf8lWev3inJP772zUOWh9BWSGQMQnRFgNb0bolbXP9T5PkvLb+TvaPxGelpa7vPv1Djeu1Pgt/yMD5Ljboiy0WRlJ9ohOhFR0mB1/Vstela6JD3RfJpXyj6WXmg6/SSl91l5Toh6nHxXN0Stri/nfqRvx6V7pbtLQnpPuipdlpb7fnS9YPyD0s1rlI0O/epJdH259/7A3sH+yvmyivgBSu+z8pwQ9Tj5rm6IJrreP31xfqomPKsifqAbomzUL6rnhKjHyXfNsevL/T1/K20npW/zyWchmmfWntEN0Tl2/dc2omS2G6JsNFnZiXaITkSUNMyx648mt9K2U/o2n3wWonlm7RkQbfPJZyGaZ9aeAdE2n3wWonlm7RkQbfPJZyGaZ9ae0Q3ROV7hl7/Oi5wW9eBDDNnjboiyUbumphGiJijbZv1XDXu1dcZSrPKJnfKpnlPK313nch9QepeU64OoS8r1dUPUPRA+CEDgfyHwCyZFNg/TyJtGAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=168x168>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.visualize import visualize\n",
    "\n",
    "rand_index = torch.randint(0, len(test_dataset), (1,)).item()\n",
    "data_sample, label_sample = test_dataset[rand_index]\n",
    "\n",
    "visualize(data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64])\n",
      "tensor([[ 0.5399,  0.0587,  0.1732,  0.7367, -0.1031, -0.1225, -0.3582,  0.0923,\n",
      "          0.3791, -0.3949,  0.2286, -0.4746,  0.1799, -0.0225, -0.3179, -0.5467,\n",
      "         -0.4071,  0.6075,  0.7798, -0.2108,  0.1190, -0.0840,  0.2573, -0.3491,\n",
      "         -0.0726, -0.4471, -0.5401,  0.4049, -0.3248,  0.2286, -0.3571,  0.0394,\n",
      "          0.6092,  0.0296, -0.6772,  0.3623, -0.2981,  0.6799,  0.0569, -0.0768,\n",
      "         -0.3713,  0.4395, -0.2888,  0.4784, -0.2708,  0.2802, -0.1539,  0.1971,\n",
      "          0.3517,  0.2718,  0.3621,  0.4258, -0.1593, -0.2432, -0.1997, -0.5023,\n",
      "         -0.1667,  0.1667, -0.5376, -0.0061,  0.3273,  0.2473,  0.3639,  0.1727]],\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAGAYABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/AO11v/kET/8AAf8A0IVzFt/F+Fd7oH/IEt/+Bf8AoRryU9KztS/5Zfj/AErc0b/kFQf8C/8AQjW34q/5Fu7/AOAf+hrXOeD/APl9/wCAf+zVh+Jv+Rhuv+Af+gCu4u/+PV/w/nXMav8A8sf+Bf0rlrz/AI+3/D+VdX4I/wCRwsP+2n/otq9ssv8Alp+H9a8s8bf8jfff9s//AEWtSXf/AB6v+H86don/AC3/AOA/1rmvEP8AyHbn/gP/AKCKl1X/AJBsv4fzFcrP/D+Neq+C/wDkUrH/ALaf+jGrkdB/5DVv/wAC/wDQTV/xb/y5/wDA/wD2Wl0n/kGQ/wDAv/QjXoniD/kCXH/Af/QhXjXjb/lx/wC2n/stdt4H/wCROsP+2n/oxqy/BX/I3WP/AG0/9FtXbeMP+XL/AIH/AOy1xU/+ub8P5VQ8J/8AIzWf/A//AEBq3/HH/Lh/20/9lrb8K/8AIt2n/A//AENq4nQf+Q1b/wDAv/QTWz4i/wCXb/gX9Km0z/kHRfj/ADNbsn+rNNg/iq2n3BXmkv8AqzUUfesXUf8Aj+k/D+Qrq9N/5CEX4/yNUvG3/Lj/ANtP/Zam0L/kDW//AAL/ANCNd1J/qzSW/wDF+FVLr/j5f8P5V//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAAGCAAAAADvMhYSAAAAwUlEQVR4Ae3TPWqCQRAA0CSFBIQERDyBVYyVnbX4U9nkBGlyhhQWilewFSHwVRYi6AHEwjJttDMg6Ww0XSD4tvEG2+wWj2FZZnZn2Nv1zWWt+Mg2R/zjnnWWOWaXGV944JbfLLDPEgd8Yjj/LJ4z5P8Un/jODza5YI0dLplxyCl7nPHIHd8Ycr6KJ2xxwyqL/GWe9wwVz+Icv1hheF24T+NqP+R5sPPDOyaidSANIFrrQ+E0gDSAyB2IXD79gMgD+AfMfSChHD4EOAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=384x6>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = autoencoder.encode(data_sample.unsqueeze(0).to(device)) # Add batch dimension\n",
    "encoding\n",
    "print(encoding.shape)\n",
    "print(encoding)\n",
    "visualize(encoding.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5399,  0.0587,  0.1732,  0.7367, -0.1031, -0.1225, -0.3582,  0.0923,\n",
       "          0.3791, -0.3949,  0.2286, -0.4746,  0.1799, -0.0225, -0.3179, -0.5467,\n",
       "         -0.4071,  0.6075,  0.7798, -0.2108,  0.1190, -0.0840,  0.2573, -0.3491,\n",
       "         -0.0726, -0.4471, -0.5401,  0.4049, -0.3248,  0.2286, -0.3571,  0.0394,\n",
       "          0.6092,  0.0296, -0.6772,  0.3623, -0.2981,  0.6799,  0.0569, -0.0768,\n",
       "         -0.3713,  0.4395, -0.2888,  0.4784, -0.2708,  0.2802, -0.1539,  0.1971,\n",
       "          0.3517,  0.2718,  0.3621,  0.4258, -0.1593, -0.2432, -0.1997, -0.5023,\n",
       "         -0.1667,  0.1667, -0.5376, -0.0061,  0.3273,  0.2473,  0.3639,  0.1727]],\n",
       "       grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKgAAACoCAAAAABRIPpoAAAEAUlEQVR4Ae2aS49MQRiGe9wZk2m3mIgYkWBh4QeY8AMQkYiIFYnEWmIr8QtsrMQKP8FybGYIESHitkFCLIgQDGMwbsnzzuLI0VNVuo7pSt5ZPP1Nne9UVz91vlPVl1bLfzZgAzZgAzZgAzZgAzZgAzZgAzZgAzZgAzZgAzZgAzZgA71ooK/7Qc2ni364CH6B3+B3+BN2g3ndnPw/z/VAc9u20dxGk6t+ASNYB/fBw5WWxcSq8V/Eb+F5eBF+gKnw1KcaC+XbaMhQ6vFijCZU/VIknIZH4CDUai5O0zJZOao9gNb9q7TrLvGOOB7FGPVA4yc1LtNG4zzFZ2npDuQr6ThZx+AAnICXoSr6CbH2/IeID8JlcAfcCy9B7QcIA/DUBwQlH7bRZGWBE4oxGqh6bQWGebUn4XL4Gh6At6HWesIZ3OVxJdwN9WTbiGXoB3EMijHqgcZMZ0qOjabYismNqvrt9LQETsFT8CbstF4rc4IcTdxXYt1JEt5aVHog7G34Gs09Pzaa22ig6lXRem+u+D0jGIWd6l0VvZacnbBa43doSf1U31OPtoyw0Ywy6aoYo4GqV7Wu4DUthNrJ6zQdrda+WobIPAc3QL3TV+Z9WhQrn4YZyJzuCdWeizHqgVanM0dsozksVvsIVL1Sn/EwDVfBo/As/AS1/x8hPgOHoeqdsPWSB7Fe0RpKpz2Ap14O89FG87lUT8UYrS+2f6jQ4TZtV+AWqDvAY2J9K6caX0OL6lc5ovYJ4xzdA7VnIGzVbakH9dwpR+09x/qL6bkh2mgzU1LM1Ku8OkrQivyR4yfgBajq3kSsLlTXqvFHtI9B1fgg8S1YX83rLdV656S/3BnU3nMsZuo90NzXTjFGA1UvL1qXb/DPfrgLboQD8Bq8Dl/BfjhSiZ8S98FUFGPUA02d2lC+jYYMpR6Pqnp1qnX8Hv88gHrPrntCfb3Wb/lWk6lYOdo/qM94eurjXcVl2micp/isYowmVL1evSpXVL3XrWg11zd3ei+gX+PoEz+v9XVjc9FSzDXqgea+PJKrPn4AbVK1sotTtLjq4x02meliym23GKONVL3qenNFqur9My3e4VfEzGFYzDXqgea+ShqselW69vZvGLc+5at/AhDzojz1MZZScmw0xVZMbjFGG6l61fVzROkzQN0BFGsnkLriF2PUA40pkJQcG02xFZPbSNVrmtbz/LoDtIkHob7Z1zfy8bXvqUdeRthoRpl0VYzRRqpenQ5hQiu7vrnbSou+06//Dmf2OSjGqAc6+0SmH7XRdGezn9FI1Wt9f8gzj8EXcBxOwlR46lONhfJtNGQo9XgxRrUUp768hPx/exdff4JijHqg9cnrrsVGu/NXP/s3vQ590mHUE6wAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=168x168>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoding = autoencoder.decode(encoding)\n",
    "visualize(decoding.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ved å ha en flaskehals i midten av nettverket, har modellen lært seg en lav-dimensjonell representasjon av sifrene.\n",
    "\n",
    "Det morsomme er at decoder-delen av nettverket kan anvendes som en generativ modell. Inputtet vil være en vektor av lav dimensjon. Vi har også brukt `Tanh` som aktiveringsfunksjon på output fra encoderen, som betyr at decoderen alltid vil forvente tall som ligger i $\\langle-1, 1\\rangle$. \n",
    "\n",
    "Hvis vi generer en lav-dimensjonal vektor med tilfeldige tall, og bruker dette som input til decoderen, får vi et _syntetisk_ siffer som output. Den lav-dimensjonale vektoren kalles i faglitteraturen for en _latent_ representasjon av et siffer. Dette fordi verdiene er \"skjulte\", altså at de ikke kan observeres på forhånd bare gjennom datasettet. \n",
    "\n",
    "Jeg skrev [masteroppgaven min](https://ntnuopen.ntnu.no/ntnu-xmlui/handle/11250/3095628) om latente representasjoner i diffusjonsmodeller. Bare ta en titt 😄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKgAAACoCAAAAABRIPpoAAAEcklEQVR4Ae2ZS6hNURjHcT0ublzvTCgmipRHoW66JiZeI5kqUjJQDEgZGJGxGDFgoJjIgJEJJYM7cCNhcs9VHkke5z5cb/n972DXOWufvfbZxdL/Dn7nu2vttc7ev69v7bX3mTDBfzZgAzZgAzZgAzZgAzZgA/+PgYl/61Iav/hX7qlMyu39hzp9olUnw0arNtpYfBHfoHRMYUQn7IDT4BfYDZfDLjgDToY34DBU1WdJ8zic+qyNKmIbrcJido5kjKr4sqfeIlZdL+Co/bAXfoKP4XOo6t5NvAwuhvrKOvEaeA4OwJ+wEckY9Yk2Jq+9Fhttz1/jaJVgY3uTlqm09cAzcBUcgVfhbTgE18FR+B5qPzCHWGvCWmKtITXiEJz6kJmy7TZa1lxoXDJGC1W9HgNmcrEnoHbs2o3303INPoJf4SDsg/KxhHgvXAE1g1aGH7SEkIxRn2gohWXbbbSsudC4QlWv2lzIHKr9YeJn8ACswez+/DstT6FmUPyQlv1wDL6B+XDq8/3E99povLP8EckYLVT1utaXfJyGm6B29bqnZ+tdx4uqd1F38zodNfgYag0hDCIZoz7RYA5LdthoSXHBYRFVr3fy95nqNdTTupKiutb3dPIxBWqU7vvdtPTCRXAA6omAMAinPqimZIeNlhQXHJaM0YiqV+V+5JpfwS64NcMtxKr668RXoFaAo8Q6Rrv6Plqy+wEamiAZoz7RJtlrq8lG29LXZHBE1as2tZPXHXwjE56EK6ESNER8C3bAPXA71FoxlfgD/A7z4dTn+4nvtdF4Z/kjkjEaUfW6YlX9J/6pwzlwIhyDuvs/IdZOvod4NtQMGjtISxEkY9QnWiSdMcfYaIytIsdGV70m/cbHXbgZ6jf358TDUFPvIF4PlT71HqZFqwdhCzj1LQRFd9totLIWA5Ixqlt0i6uJ7dbV6z3/TQbrLq93+GdpOQWL7O317ckY9YkqYdXRRqtzqZmiq17v5VS/2qtnJ5rBP3prd4h4vrrhW7gBvsi0Fwmd+iKWYo6x0RhbRY5Nxqi24S0uSUvDPI7aBmtQe/WdxAfhXCj84kPrwwjxOfhS3ZFMxqhPNDKzLQ+30ZaKIg8oVPX6Je4IU++CC+EsqLs/4ThU7zX+uwzvwAdQ6wBhBJz6CFmFDrXRQpoiDkrGaKGqV53e4/r17m4pceNg7fkv0XsM1mG5SmfoOJIx6hPNpq2K2EarsJidI+K5Xr+8r2L0ebga6lle9X6BluPwM9R9n7AtOPVt6Wsy2EabSGmrKRmjEVWfFaJdvX6F30dHP7wI9RSv9/Pt3+X1vckY9YkqYdXRRqtzqZlKVr0Ga4evZ3zd64fo0JowSvxVhwaohIr5v+I59QGFpZtttLS6wMBkjDY+mgeuqFmz7uPv6NJOfjqxlhKtA83G/WnT88JsuutQo0JPBMkY9YmSzQphoxXKzJRaZbOqcrP1qyrOtpT7Mqe+nLfwKBsNuynXk4zRcpfnUTZgAzZgAzZgAzZgAzZgA/+mgd/zT5X60jx6OQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=168x168>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent = (torch.rand(size=(1, autoencoder.bottleneck_size))-0.5)*2\n",
    "decoding = autoencoder.decode(latent.to(device))\n",
    "visualize(decoding.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultatene gjenspeiler den enkle arkitekturen som er valgt, og fåtallet epoker den fikk trene."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder\n",
    "\n",
    "AutoEncoders er TODO\n",
    "\n",
    "<img src=\"../res/autoencoder.png\" height=\"300px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Pipeline of processing operations\n",
    "image_processing = transforms.Compose([\n",
    "    transforms.ToTensor(), # Cast into torch.Tensor\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Pixel-values will range in [-1, 1]\n",
    "])\n",
    "\n",
    "train_dataset = MNIST(root='../data', train=True, transform=image_processing, download=True)\n",
    "test_dataset = MNIST(root='../data', train=False, transform=image_processing, download=True) # Test data for later\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32) # Iterable that provides 16 data samples each iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En AutoEncoder består av to komponenter:\n",
    "- Encoder\n",
    "    - En sekvens med lineære lag som reduserer dimensjonaliteten.\n",
    "    - Ender opp med en vektor med veldig få dimensjoner kontra 784 fra rådata.\n",
    "- Decoder\n",
    "    - En sekvens med lineære lag som rekonstruerer inputten fra den korte vektoren.\n",
    "\n",
    "Vi tar i bruk `nn.Sequential` for å lage sekvenser av lag som dataen flyter gjennom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=200, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=200, out_features=42, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=42, out_features=16, bias=True)\n",
       "    (5): Tanh()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=42, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=42, out_features=200, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=200, out_features=784, bias=True)\n",
       "    (5): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28, out_features=200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=200, out_features=42),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=42, out_features=16),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "             nn.Linear(in_features=16, out_features=42),\n",
    "             nn.Tanh(),\n",
    "             nn.Linear(in_features=42, out_features=200),\n",
    "             nn.Tanh(),\n",
    "             nn.Linear(200, 28*28),\n",
    "             nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def encode(self, data):\n",
    "        out = torch.flatten(data, start_dim=1, end_dim=-1)\n",
    "        out = self.encoder(out)\n",
    "        return out\n",
    "    \n",
    "    def decode(self, data):\n",
    "        out = self.decoder(data)\n",
    "        return out.reshape(-1, 1, 28, 28)\n",
    "\n",
    "    def forward(self, data):\n",
    "        out = self.encode(data)\n",
    "        out = self.decode(out)\n",
    "        return out\n",
    "    \n",
    "autoencoder = AutoEncoder()\n",
    "autoencoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1875/1875 [00:07<00:00, 258.76batch/s, loss=0.108]\n",
      "Epoch 1: 100%|██████████| 1875/1875 [00:07<00:00, 262.93batch/s, loss=0.0919]\n",
      "Epoch 2: 100%|██████████| 1875/1875 [00:07<00:00, 253.47batch/s, loss=0.071] \n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    with tqdm(train_loader, unit=\"batch\") as pbar:\n",
    "        pbar.set_description(f\"Epoch {epoch}\")\n",
    "        for i, (data, _) in enumerate(pbar): # no need for labels\n",
    "            data = data.to(device)\n",
    "            pred = autoencoder.forward(data) # Query model for predictions\n",
    "            loss = loss_fn(pred, data)\n",
    "            \n",
    "            loss.backward() # Propagate the computational graph and calculate gradients\n",
    "            optimizer.step() # Uses the calculated gradients on the registered parameters to perform an update\n",
    "            optimizer.zero_grad() # Remove the gradients\n",
    "\n",
    "            pbar.set_postfix(loss=loss.cpu().item()) if i%40 == 0 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi studerer nå hvordan modellen klarer å rekonstruere et siffer fra datasettet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCACoAKgBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiivUdF+Dv9r6tBY/295Xm7vn+x7sYUnpvHpWb8TPhn/wAK6/sv/ib/ANofb/N/5dvK2bNn+22c7/bpXAUUUUUUUUUUUUUUUUUVrWVlby2iO8eWOcncfWvsn/hHdK0n/TrG18q5i+4/mM2M8HgkjoTXh/7Q1zLcf8I55r7tv2nHAH/PKvEKKKKKKKKKKKKKKKKK6Pwp4c1bxB9r/su18/yNnmfvFXbu3Y+8R6Gvpb4faDqWneB9Otbq28uePzdy+YpxmRyOQcdCKsfEbxHpP/CB6l/pf/PL/lm//PVPavmHxXqVpqH2T7LL5mzfu+UjGduOo9q5ypba2lu7hYIE3yNnC5AzgZ717r8BNF1C3/4SDzbfbu+zY+dT/wA9fevTr7QdSmvJHS2ypxg719B718b0UUUUUUUUUUVYsrb7ZdpBv2bs/NjOMAn+le7/AAK8Nf8AIf8A9L/59/8Aln/10969vtx9ggW1/wBZsz83TOTnp+NfMXivx7/bHhm7sP7N8nzdnz+fuxh1PTaPSvMHfdjjGKbXSeAtN/tfxrp9j53leb5nz7d2MRsemR6V9RfDzw1/wj39pf6X9o8/yv8Alns27d/uc9a0dW8Xf2Xqc1n9h83y9vz+btzlQem0+tfFFFFFFFFFFFFFdr8PtJstR8cada3UHmQSebuXewziNyOQc9QK+nfBeg6Zof27+zrbyfO8vzP3jNnG7H3ifU15/wCPfGniDSfGuoWNjqHlW0Xl7E8mNsZjUnkqT1Jr50kvbiWMo8mVPUbRUFFes/DXSbKH4gaY6QYYebg72/55P719J6VGkfnbBjO3P61wniz/AJGa8/4B/wCgLXydRRRRRRRRRRRX0J8OtF1C08d6bPPb7I183Lb1OMxOOxr2PW723s/I8+TZu3Y+UnOMen1r5X+Kd7bzfEjVpI5MqfJwcH/nilcRZWVxqN2lrax+ZPJnau4DOASeTx0Brt/DHw+8UXn2ryNL37dmf9IiGM7vVq918H+GdY07wtZWl1Z+XPHv3L5qHGXYjkHHQivSqY0qR43HGfavmP4r3MX/AAszV/n/AOePY/8APFK8gooooooooooor7X0rwj/AGXqUN59u83y8/J5W3OQR13H1rmfi54l/wCEd/sf/RPtHn+d/wAtNm3b5fsc9a+Z/Fepf2x4lu7/AMnyfN2fJu3Ywijrgelej+C/hh/xVtj/AMTj/np/y7f9M2/26948O+Ef7B+0/wCnef523/lltxjP+0fWtOW/+xyGDy9+3+LdjOea0sVynjPxP/wjf2H/AEP7R9o8z/lrs27dvsc/er5i+IPiH+1PHOo3n2XyvM8r5PM3YxEg64HpXFUUUUUUUUUUUV9+15X8ZLK3vP7F+0R79nn7fmIxny/T6Vyek/D7wvqOmQ3V1pfmTPu3N9olGcEgcBsdAK9psvDGj6ddpdWtn5c8edrea5xkYPBOOhNV/EmpXen/AGX7LL5e/fu+UHOMY6j3rxXxX498TWnia7gg1LZGuzC+RGcZRT3WvomvI/jdczW/9heU+3d9ozwD/wA86+cNekebWriSQ5Y7cnH+yKzaKKKKKKKKKKK+ufDHifR9R8Q2tra3nmTPv2r5TjOEJPJGOgNeiCivOfEfxG8Kf2Dc/wDE1/u/8u8v94f7NeH+Pda0/wAT/wBn/wBj3H2n7P5nm/Iybd23H3gM/dPT0r0/4a6DqUvw/wBMdLbKnzcHev8Az1f3rvPiVKkPw/1R3OFHlZOP+mqV8q+MbmG4+xeU+7bvzwR/drl6KKKKKKKKKKKK7/wh8QP7E8U2eo/2Z53k7/3f2jbnKMvXafWvY9M+N39o+b/xT3l+Xj/l9znOf+mftWfqX7QH9n6hLa/8Ix5mzHzfb8ZyAenl+9eF6j4l/tCwltfsnl78fN5mcYIPTHtUWg/8vH/Af619Y/Cj/kmmkf8Abb/0c9ZPxT1vzPhvqy/Z8Z8nnf8A9Nk9q+XNVuftHlfJt25759KzqKKKKKKKKKKKKdHI8UgdDhh0OK0LbXtTs93kXOzfjd+7U5x9R71XudRu7u4aeeXfI2MttAzgY7Cqtdx8PNNtNQ/tL7VF5mzytvzEYzvz0PtX1D4Dt4rTwXp8ECbI18zC5JxmRj3rwfxp4i1W78JX0E91vjby8r5ajOJFPYV5A8jyY3HOKbRRRRRRRRRRRRRRRTo43lkCIMsegzXuf7P2nXX/ABUX7r/n2/iH/TX3r6Bs42itERxhhnI/GvgmiiiiiiiiiiiiiiiiitLQLX7ZrVvb79m/d82M4wpP9K+kfgjpf9nf27++8zzPs/8ADjGPM9/evWiOa+AqKKKKKKKKKKKKKKKKK2vCf/IzWf8AwP8A9Aavpj4SH/kMf9sf/albut61qFpq88EFxsjXbhdinGVB7ivjCiiiiiiiiiiiiiiiiitrwn/yM1n/AMD/APQGr6W+E0qR/wBr7zjPk44/368u+LFzF/wszV/n/wCePY/88UryCiiiiiiiiiiiiiiiiiruk3/9l6nDeeV5vl7vk3bc5Ujrg+tej+F/jL/wjf2r/iQ/aPtGz/l82bdu7/YOfvVyfizxh/wk/ia71j7B9m+0bP3Xnb9u1FXrtGfu56d65eiiiiiiiiiiiiiiiiiiiiiiiiiiiiiv/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKgAAACoCAAAAABRIPpoAAADFUlEQVR4Ae2aq28WQRTFS8t/QDWyLaGqqeThwJIGJGgweAKyAUdtAxLdD4XAEhQEUDw0OB4aVyDnmEmmMztndpL2hlNxMt99zM7+bu/Ofrvf0pL/TMAETMAETMAETMAETMAETMAETMAETMAETMAETMAETMAETiKBU6MWtYuJ7kFXRk2azLOcjE/00AsdXR4THU10QNdvYE0foZ+hm6NX+W8+l340VBP9b4mennPmZ5F8AOXl41F1uk/wUq9XI3On/0dzJvMsJjqPX54dhuisrn+GE1+HLhLNeewkkWu5u8EShqgX2lBNKcREJVwNwZ1dfxFTU39g/AD6u3BIft/n/cCTQkzd7NLX+eheE9WZ1TPCEJW7fhUn/hj6B3oT+gWaC68MzGJ8HtNiCUPUC20ppxJjogqtlli567cx6xb0G/Rddhx692Bn17PfvddnqI7R4GYaDT8MUbnrrwEVu/gVxr8SePcxvgs9A2Uk9ScsVAwFCUPUCxWq2hRqok2YhCD5zd0hJmcXn8eY9/a7GKff3/kW71wSfwdjf68HhmMXN9PoEoQhKu/16d59Cdj2oFeg9D7H+CH0bWLnOzsYZAlD1AuVazuRYKITgGS33PWvcYgL0H0oO51P7xew3IbyvR5vJm7BwlwMZXHpZWQTCSY6AUh2hyEq3+FfBYsXUCaz62/Awl1+C+M3Scw2xh+gfRKGqBfaV+BylomW2fR55L3+JY6zCeUd/gHG6TM9LoXXhPf48JWmGerSz4B3ZKqJHollhjEMUbnrCYVP8Kg5ph2YeA/wFOP8mpBn1S1hiHqh9ULqXhPVmdUz5Dv8+nT08qndOj6stCQ0xLj0DZCkEBOVcDUEhyHaudeXEGzAwX7nXl+KVO1hiHqhammn4k10ipDqH9z1l3F8lulQXUs13qWv4ulwmmgHtGpKGKKDu577O/t9USWkOsMQ9ULV0k7Fm+gUIdU/uOv5mIBl4q901AWV4l36Epleu4n2kivlhSE6uOu5138Hlr7f24cnGqb0Xmjpf63XHoZo7wk6zwRMwARMwARMIAaBv6BCS45fbx86AAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=168x168>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from utils.visualize import visualize\n",
    "\n",
    "\n",
    "rand_index = torch.randint(0, len(train_dataset), (1,)).item()\n",
    "data_sample, label_sample = train_dataset[rand_index]\n",
    "\n",
    "visualize(data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16])\n",
      "tensor([[-0.7283, -0.6815, -0.1664, -0.6456, -0.4464,  0.3966, -0.6303, -0.1945,\n",
      "          0.2879,  0.5607, -0.4341, -0.2634, -0.8297,  0.4171,  0.2058, -0.0583]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAGAGABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APIk+8K6bwv/AMvf/AP/AGaqWtf8hef/AID/AOgiul8I/wDI0Wf/AAP/ANAar/xP/wCYV/22/wDZKx9H/wCQXD/wL/0I16rYf8fsf4/yNcz8TP8AmF/9tf8A2SuQtv8Aj3X8f51ifDv/AJHvTf8Atr/6KevatQ/5Z/j/AErmL7/j8k/D+Qr/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGAAAAAGCAAAAAAZXsSjAAAAQElEQVR4AWNUYgABNjDpBCYPg0lJMJkDJmvBpDmYtAOTEF1NYLYomNwBJueDyadg8j6YZAKTNCRGLSAYuDQPIgBQDwaEVwxoJQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=96x6>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = autoencoder.encode(data_sample[None, ...].to(device)) # Add batch dimension\n",
    "encoding\n",
    "print(encoding.shape)\n",
    "print(encoding)\n",
    "visualize(encoding[None, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7283, -0.6815, -0.1664, -0.6456, -0.4464,  0.3966, -0.6303, -0.1945,\n",
       "          0.2879,  0.5607, -0.4341, -0.2634, -0.8297,  0.4171,  0.2058, -0.0583]],\n",
       "       device='cuda:0', grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKgAAACoCAAAAABRIPpoAAAENElEQVR4Ae2bTW8NURjHr7fSRiMVFZSol0UllhIqRHJDYkPiI6gNX8XCnpW9FQvfQLykYUFJKtKIlKQtVdrQek1+f4tJ5s6dOTNHmsO/i38fz5y3+T3znOfccdtq+ccETMAETMAETMAETMAETODfIbAm7q1kh/sVdei1UUf7i4N5obHhmmhsouvjDpjNeo0cK/cd+riRarVM9L8lmk/TYBR6evrp9wNdQX9mVG168MjWxMt4vqHd9wc/o0CKKCYaESZDJUO0Zq1Xzm7kXg+jbXQCfYouoMpr8RjGo76fsWdR7RKYhZIMUS+0MIY1L5hoTXCF3WpmvbrtY9hL6F5UVfs5tur+Ouzt6Ag6hN5D59Aq4tBXoRTSxkRDaFVpmwzRmlmvKt8GxUlU5/OH2NOosl4TDOM5h35Ax1G1wSyRZIh6oSWRDL5sosHISjrUzPp+hr2IqnY/wX6GquJjtjTBGf5xCp1Cb6HZljgKxaEvRFPzgonWBFfYLRmiwVmvE/sR7nw/qip/FXsx49Hnd53tL+Dfik6is6je+GGWSDJEvdCSSAZfNtFgZCUdgrO+jwEvozrnv8B+jGazeBOeMXQQ1WQz2Mp6zEri0FfCFNDIRANgVWqaDNGArFft3sn96729PpXrvdwSfp0EtBvswXMe3YLOo3fQr2h1SYaoF1o9qNVammg1TtVbBWf9KGNvQL+gE2gvqgANYo+hB1GJ3ti/zni0k+gzQsbdwXToO0Bp5DLRRvg6dE6GaEDW655U61XNVbuHuP8T6A5UbU5ja4Lv2Hp3tw17AF1Aq9T9ZIh6ocQ0ophoRJgMFZD1qssf6abqrM5tPEdR7QbKZZ0H1FKfBV7S5hWqc0KVKk9zf39UGCKqkykiTIZKhmhA1utN3RT3p1O9aro+yyvH9f0cVfZjtNRe8Q77Gip7CdtZD4ZVkWSeUS809vMRkPWa+gG/rqC7UOW4BprGcxZVvuv0fgPPOLqChopDH0qsrL2JlhEKvZ4M0YCs1yl9ERSTqM7q8qtq9+IfQHUGeI99E62X73T1CV8YImoyz6gXGjHqDBWQ9ZpaOS5bVV62Kruy/jgu2bex59WogTr0DeB17GqiHbE0cCZDNDjru0PZzeVDqM7297Gze0X3EYquJkPUCy0KYV2/idYlV9QvWtar1o8wTx+qs/2jopkD/Q59ILDS5iZaiiiwQTJEo2V9D4QOZDi9xZ5BtSdUf2OfGeaPmQxRLzQfvGYeE23GL987QtYro1XfR5lhBdX7fO0GTfJdi3bo88Fr5jHRZvzyvZMhGiHrdfeb+aXv3ki1G2gC1/r8M7LanmSeUS809qMSIetVx+dY2V1Utf469hs0+7d4OILFoQ9GVtLBREsABV9OhqiKcPD95TvojnXO1//ZfaLRcr5pLU8yRL3QWvHt0slEu8DxJRMwAROoQOA3z7Z9vqjglH8AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=168x168>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoding = autoencoder.decode(encoding)\n",
    "visualize(decoding.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ved å ha en flaskehals i midten av nettverket, har modellen lært seg en lav-dimensjonell representasjon av sifrene.\n",
    "\n",
    "Det morsomme er at decoder-delen av nettverket kan anvendes som en generativ modell. Inputtet vil være en vektor av lav dimensjon. Vi har også brukt `Tanh` som aktiveringsfunksjon på output fra encoderen, som betyr at decoderen alltid vil forvente tall som ligger i $\\langle-1, 1\\rangle$. \n",
    "\n",
    "Hvis vi generer en 16-dimensjonal vektor med tilfeldige tall, og bruker dette som input til decoderen, får vi et _syntetisk_ siffer som output. Den 16-dimensjonale vektoren vil i faglitteraturen kalles for en _latent_ representasjon av et siffer.\n",
    "\n",
    "Jeg skrev [masteroppgaven min](https://willdalh.github.io/thesis/thesis.pdf) om latente representasjoner i diffusjonsmodeller. Bare ta en titt 😄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKgAAACoCAAAAABRIPpoAAAEt0lEQVR4Ae2aTYtcRRSGx6iJ5sMMM6AhYVBIIBqI6DLgTnHjxgT8CSG4cCO48yeYH+AfEAKBQHZmoUshogjxa/CTEUcCIVEzOGaSqPA8WZzO9J2u6i7CFJ5ZPH363Kq6VW/1e6vuvTM3l3+pQCrw/1LgoVbDtaF/aW4onuVcO2ap/CDrZkdbq52KtlZ0StdbLVZ+jJ49C9+FJ+Bv8Ay8Av+Gtcipr1VsUvlUdJJCtce7UTQat2iQVthJ2YfhMfgmfAPuhmKNjwvwLFyGt2E5ulE0O1o+qWUlU9EyncpLPVJSVHdLy+/hYy98B74KzXtluEvmV3gOrkJhGe8IQnowzKkflGbKA6nolMINVutG0SLX699/GK1uvUO8BA9BV39d7NFvyb8FP4W3oCj3u+W7UTQ7Gma5SZiKNpExNFLkestHn3oF0On7ObwBr8IP4HvwDxjrkqhGTn21ZBMqpKITBKo+3I2iFa5XBP17my86/SbxFfg+PA/jyk5iJnSjaHZ0pnkeUzkVHSPKTKlq17vDdyKOc2qf3X1IfBGW+D3v62eatwaV00wNRBxpohtFq13vWu97upcYs67/mHh9RIX7v+j0+7Nl37tRNDtaNqHlpVLRcq3KSla73if5B2ldv/9OLIfu3/W7dS3jkwGqjsHmnUBO/RiZZkqlojPJN6ZyN4pWu14/PsmY3clfJl4NKjh6mzZ+NByN+//ofVs2s/nq0Y2i2dEw103CVLSJjKERrRYSk0LX60WKvQiXoe/lfcfns/158nIfsfcFXxKvQT1uJ5xc3/rFqwEF53Lq1aEdU9F2Wnb2G612vRVcx411evSvO/9nkMJ7AdduHf09eV2/QexRryf+v64l44qfv1GkaohUtKGYNNWNotq3Yvg6Me7DzWx26Dytup+3/HUyXhMOE3sF8D3gApmfoTBv3I2i2dEwg03CVLSJjKGRate7vkunw3U57gF2cQIdHXcCxgscfQpa9waxzwp+IXbFJ7yHnPqoRos4FW2hYmyjG0UrXB997XrtCv5XGLjjdt8uXa/dCdjCE5TX13rfWj+St5YlN+8fwqm2a9jN1GdHW/+EulG0yPV60DE9jlSHoE/nVoh1q/fmltTXru/qazvGR/h4Gn4GP4c63esJiXvoRtHsaJy2FnEq2kLF2MYE1yu4bvXJ/AK1T8L98Ceoc70m3CTzDYxTtpfMKXgc/gk/gl4ldD2JEcR2Rg5sty/Z0dYzkoq2VnSC66MHXdlfoAevwwNwHa7Aq/A7uA9eg/r9FeIT0JK+77tORsQzhnS+uYtiNInTTE1kDI10o2iR6x3NXca3B7qmzxMvwiXoFeA14tPQFdz9gPv2W+S/gK7y7iVsP12PMA8A3fxGs6Otfw0TXO/p9OMaXy5Bnfs28WHoau7VwGnaRf4GNL9CfBb+AH0asPXenoK51itDQ6aZGopJU90oGh+wVYhgNf/P9ij1noMvw+eh+/yvib+Cn0Dv+u8Qu7K7ByAxiG4UzY4OzuGUB1LRKYUbrDal64fac4LcQNi0jtbj1hraww+1aT6nfmt96o+movWabV2jG0W3HkYeTQVSgVQgFUgFUoFUIBVIBVKBVCAVSAVSge2swH+w4qpObvxT7QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=168x168>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent = (torch.rand(size=(1, 16))-0.5)*2\n",
    "decoding = autoencoder.decode(latent.to(device))\n",
    "visualize(decoding.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultatene gjenspeiler den enkle arkitekturen som er valgt. Det er flere forbedringer man kan gjøre på arkitekturen for å få mer lovende sifre. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO FIX Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=32*7*7, out_features=512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=512, out_features=42),\n",
    "            nn.Linear(in_features=42, out_features=16),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=16, out_features=42),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=42, out_features=512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=512, out_features=32*7*7),\n",
    "            nn.Tanh(),\n",
    "            nn.Unflatten(1, (32, 7, 7)),\n",
    "            nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose2d(in_channels=16, out_channels=1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def encode(self, data):\n",
    "        # out = torch.flatten(data, start_dim=1, end_dim=-1)\n",
    "        out = self.encoder(data)\n",
    "        return out\n",
    "    \n",
    "    def decode(self, data):\n",
    "        out = self.decoder(data)\n",
    "        return out.reshape(-1, 1, 28, 28)\n",
    "\n",
    "    def forward(self, data):\n",
    "        out = self.encode(data)\n",
    "        out = self.decode(out)\n",
    "        return out\n",
    "    \n",
    "autoencoder = AutoEncoder()\n",
    "autoencoder.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

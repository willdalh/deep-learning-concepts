{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    import torch\n",
    "    from IPython.core.display import HTML\n",
    "    from IPython.display import display\n",
    "    import os\n",
    "    print(\"Running in Google Colab\")\n",
    "    if not torch.cuda.is_available():\n",
    "        display(HTML(\"\"\"<div style=\"background-color: red; font-weight: bold; color: white;\">You have not activated a GPU in Google Colab. Follow the instructions in the <code style=\"color: white;\">README</code></div>\"\"\"))\n",
    "    print(\"Installing requirements\")\n",
    "    requirements_url = \"https://raw.githubusercontent.com/willdalh/ml-course/main/requirements.txt\"\n",
    "    if not os.path.exists('requirements.txt'):\n",
    "        !wget {requirements_url}\n",
    "    %pip install --user -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nevrale nettverk med PyTorch\n",
    "Nevrale nettverk har tilsynelatende komplekse strukturer. Likevel består de av flere enkle og isolerte komponenter. Disse finner man i `torch.nn`. \n",
    "\n",
    "De fleste komponentene blir et _lag_ i nettverket, men det finnes komponenter som anvendes på eksisterende lag (feks aktiveringsfunksjoner). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Den enkleste komponenten man finner i nevrale nettverk er lineære lag. Matematisk gjør den en lineær transformasjon fra et vektorrom til et annet. Feks kan det lineære laget ta inn en vektor med 3 features, og outputte en vektor med 2 features:\n",
    "\n",
    "\n",
    "\n",
    "<div >\n",
    "<img src=\"../res/nn_3in_2out.png\" width=\"30%\" alt=\"SVG Image\"/>\n",
    "</div>\n",
    "\n",
    "Hver node representerer en numerisk verdi. En kobling mellom to noder indikerer en vekt, som ganges sammen med verdien fra en node til venstre og summeres sammen med alle de andre koblingene som går inn i en node til høyre. Vi kommer til å erfare at dette utføres som én matriseoperasjon.\n",
    "\n",
    "\n",
    "I PyTorch lager vi lineære lag gjennom `torch.nn.Linear`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=3, out_features=2, bias=True)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.Linear(in_features=3, out_features=2) # Construct layer\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vector: tensor([[1., 1., 1.]])\n",
      "Output vector: tensor([[-0.0365,  0.0958]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "data = torch.Tensor([[1, 1, 1]])\n",
    "print(f\"Input vector: {data}\")\n",
    "output = layer(data) # Feed data into layer\n",
    "print(f\"Output vector: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vektoren, som består av 3 enere, har blitt til transformert til en vektor med 2 tall. Vi studerer _vektene_ til det lineære laget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1089, -0.5741,  0.2255],\n",
      "        [-0.1529,  0.2941, -0.1458]], requires_grad=True)\n",
      "Weight shape: torch.Size([2, 3])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(layer.weight)\n",
    "print(f\"Weight shape: {layer.weight.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrisen viser tallene som tilhører hver linje som trekkes mellom nodene i figuren over. \n",
    "\n",
    "I tillegg til vektene, har lineære lag et konstantledd. Denne adderes på resultatet fra matriseoperasjonen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.2032, 0.1004], requires_grad=True)\n",
      "Bias shape: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print(layer.bias)\n",
    "print(f\"Bias shape: {layer.bias.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Når man sender input-vektoren inn skjer følgende operasjon (hvor `@` er matrisemultiplikasjon):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0365,  0.0958]], grad_fn=<AddBackward0>)\n",
      "data @ layer.weight.T + layer.bias is similar to layer(data): True\n"
     ]
    }
   ],
   "source": [
    "print(data @ layer.weight.T + layer.bias)\n",
    "print(f\"data @ layer.weight.T + layer.bias is similar to layer(data): {(data @ layer.weight.T + layer.bias == layer(data)).all()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi ser fra resultatet over at det stemmer.\n",
    "\n",
    "\n",
    "Vektene og biaset utgjør til sammen **parametrene** for dette lineære laget, og er verdiene som endres når man trener nettverket. Andre typer lag har også vekter og bias, men hvordan de er strukturert og brukes varierer. Til denne introduksjonen begrenser vi oss til lineære lag, men sjekk ut `bonus_convnet.ipynb` for å se hvordan man bruker konvolusjonelle lag. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aktiveringsfunksjoner\n",
    "\n",
    "Det lineære laget utfører en lineær operasjon. Fleksibiliteten av nevrale nettverk kommer derimot av såkalte _aktiveringsfunksjoner_ som utfører ikke-lineære operasjoner på data. Disse inneholder **vanligvis ikke** trenbare parametre. De enkleste opererer på hvert element av en tensor individuelt, som feks Tanh. Av denne grunn modifiseres ikke _shapen_ til tensoren. Vi ser på et en-dimensjonalt-case for å visualisere det enkelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt # Library for visualization\n",
    "tanh = nn.Tanh()\n",
    "assert not hasattr(tanh, \"weight\") # No learnable weights\n",
    "\n",
    "data = torch.linspace(start=-6, end=6, steps=100) # Vector with 100 elements increasing from -6 to 6 \n",
    "output = tanh(data)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "ax.plot(data, output)\n",
    "ax.set_xlabel(\"Input scalar\")\n",
    "ax.set_ylabel(\"Tanh output\")\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En annen viktig er `nn.Softmax`, og brukes til å transformere en vektor til elementer som summeres til 1. \n",
    "\n",
    "Dette gjør den litt annerledes enn Tanh, siden vi må spesifisere en av shape-dimensjonene som skal summeres til 1.\n",
    "\n",
    "For denne anledningen tar vi også i bruk `nn.functional`, som er et delbibliotek som tilbyr komponentene tilstandsfrie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "tensor([[7., 6.],\n",
      "        [8., 5.],\n",
      "        [1., 3.]])\n",
      "Transformed data, normalized along columns:\n",
      "tensor([[0.7311, 0.2689],\n",
      "        [0.9526, 0.0474],\n",
      "        [0.1192, 0.8808]])\n",
      "Summing individual batch elements:\n",
      "tensor([1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(42)\n",
    "data = torch.randint(low=1, high=10, size=(3, 2)).float()\n",
    "print(f\"Original data:\\n{data}\")\n",
    "data = F.softmax(data, dim=1)\n",
    "print(f\"Transformed data, normalized along columns:\\n{data}\")\n",
    "print(f\"Summing individual batch elements:\\n{data.sum(dim=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Den gjør seg svært godt som siste lag i et nettverk vi ønsker skal modellere en sannsynlighetsfordeling (Total sannsynlighet av alle utfallene av en stokastisk variabel skal være 1). Den er feks brukt som siste lag i ChatGPT, siden språkmodeller lærer seg en betinget sannsynlighetsfordeling over ord gitt tidligere tekst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifisering av sifre\n",
    "Vi skal sette opp et nevralt nettverk som er i stand til å klassifisere sifre. For denne oppgaven tar vi i bruk det lett tilgjengelige MNIST-datasettet. Dette lastes ned gjennom torchvision-biblioteket. Torchvision-biblioteket er et hjelpebibliotek som tilbyr verktøy for Computer Vision-oppgaver. \n",
    "\n",
    "Datasett kommer vanligvis i et rå-format, og må behandles for å tilpasse det oppgaven vi skal gjøre. I dette tilfellet får vi PNG-bilder som må gjøres om til tensorer. Vi normaliserer også bildene for å få [bedre resultater](https://developers.google.com/machine-learning/data-prep/transform/normalization). Behandlingen gjøres med `torchvision.transforms`-biblioteket. \n",
    "\n",
    "Datasettet lagres i roten av prosjektet i mappen `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of digits in the training set: 60000\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Pipeline of processing operations\n",
    "image_processing = transforms.Compose([\n",
    "    transforms.ToTensor(), # Cast into torch.Tensor\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Pixel-values will range in [-1, 1]\n",
    "])\n",
    "\n",
    "train_dataset = MNIST(root='../data', train=True, transform=image_processing, download=True)\n",
    "test_dataset = MNIST(root='../data', train=False, transform=image_processing, download=True) # Test data for later\n",
    "print(f\"Number of digits in the training set: {len(train_dataset):}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I maskinlæring trener man flere epoker (iterasjoner) på hele datasettet. \n",
    "\n",
    "Hver epoke inneholder igjen flere iterasjoner som består av å oppdatere vektene basert på et lite subset av datasettet. Man kaller dette for en batch. Vi lager en `DataLoader` som batcher dataen for oss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data batch: torch.Size([32, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32) # Iterable that provides 32 data samples each iteration\n",
    "\n",
    "data, labels = next(iter(train_loader)) # Retrieve a batch of data samples and labels for inspection purposes\n",
    "print(f\"Shape of data batch: {data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensoren inneholder 32 eksemplarer, 1 fargekanal (grayscale), 28 piksler i høyden, og 28 piksler i bredden.\n",
    "Vi kan visualisere et tilfeldig eksemplar fra datasettet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42); # Set random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shown below is the digit 6, with shape torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKgAAACoCAAAAABRIPpoAAADXklEQVR4Ae2az4tOURjHX/IzlMaKWdqwtBTZTMJkg2xYyVJZYbLxByhZWNhgIwtFFkqahZKJyFIsLCghLNAgIdTnWbz3zn2fe8859yRn+lp877nf8zznnvN5OnN/eAcD/RMBERABERABERABERABEZg/BBb8m6WMc5kN6A10JWqXv097C+rJQq/jf/M10dwVEdHcRBflHnDueFMY29Cdlc4/tKta6RzRVOlHQOlliWgvfCOSiyGa7V6/GAr2R2QH7RPoJnQJ6slnOo6hl5ygYohqok4Fk20RTUbnJGbY9WsZ+gJavZs7VxxhP8DbOqJnaKn0QxZ5WiKah+NwlGKI9nrCP86Cm0/vQw5hrfMBYcUQ1UQDqhkVIqJRuAKCo3f9GIMeQe2dfXnAZSxklsMkam3zn9ihVVX6VjwJnSKaAK01pRiiEU/4tru/tK672XkT6zt6Fn3YDApwiiGqiQZUMypERKNwBQRH3+sDxhzYe/plQk2/haS1xqj0rXgSOkU0AVprSjFEO3b9UlZ5Ej3QuuKP9L5A96Lvnfh1+F9R+3rvBNbsYohqorW6ZTgR0QwQa0N0POFPEDxdS5l78hLjMPoI3Y96co6OGfQq+gG9hXqi0ntkUn0RTSXn5RVDtNeut3f83UBYj06i+zwsjm+73r4QXndiiiGqiToVTLZFNBmdk9ix620/jjnJv/HfoqvRFWiazJK2C7UvA9VxVPoqjRxtEc1BsTpGMUQ73uvXsCj73Wx1fda2VY43O5KcVWQtc3KLIaqJOhVMtkU0GZ2TKKIOmGRbRJPROYki6oBJtjvu9bHj/iDhKXoavYtuRE+h9ls+mjV5x5k959c6OFHpm0z6OSLaj18zuxiiHbv+GksL/zpn/y9/hSx78j9Ke6qJqOHYL/kfN3wziiGqiToVTLZFNBmdk9jxNW+CtGknOZf9jIH2oM+dQVV6B0yyLaLJ6JzEYoh23Os/sb7XaK6vdobsDYeDqH2x/2kdjhZDVBN1Kphsi2gyOiex415vWds5XET77/0zjHMHvY2GiEofQikmRkRjaIXEFkM0aNfbijdzmAlZfiXmFe1DFece7V8VJ6RZDFFNNKScMTEiGkNLsSIgAiIgAiIgAiIgAiIgAiIgAiIgAiIgAiIgAvOJwF/mwEqClQcOLAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=168x168>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.visualize import visualize\n",
    "\n",
    "# Get a random sample from the training dataset\n",
    "rand_index = torch.randint(0, len(train_dataset), (1,)).item()\n",
    "data_sample, label_sample = train_dataset[rand_index]\n",
    "\n",
    "print(f\"Shown below is the digit {label_sample}, with shape {data_sample.shape}\")\n",
    "visualize(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Og tensoren i seg selv ser slik ut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -0.7804, -0.4745,  0.8980,  0.9922,\n",
       "           1.0000,  0.5451, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -0.0667,  0.4196,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.5373, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9529, -0.9216,\n",
       "          -0.3725,  0.5529,  0.9373,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.8667, -0.2314, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -0.7961,  0.4196,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.5373, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -0.0824,  0.4039,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843, -0.2863, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -0.9922, -0.8510, -0.0196,  0.9137,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.8824, -0.5373, -0.6392,\n",
       "          -0.6392, -0.9843, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -0.9216,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.3804,  0.3176, -0.5608, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -0.9216,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.5373, -0.1922, -0.9137, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9373,  0.0039,\n",
       "           0.7098,  0.9843,  0.9843,  0.9843,  0.9843,  0.8510,  0.5922,\n",
       "          -0.8196, -1.0000, -1.0000, -1.0000, -1.0000, -0.7882, -0.8745,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4745,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.7333, -0.4980, -0.9137,\n",
       "          -0.2549, -0.2549, -0.2549, -0.2549, -0.2549,  0.8980,  0.4275,\n",
       "          -0.2549, -0.4196, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4745,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.8902, -0.5137, -0.2471,  0.3333,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.8196, -0.3490, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.8431,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9686,  0.7725,  0.8980,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.8824, -0.5451, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.9922,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843, -0.4902, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.9922,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843, -0.4902, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.9922,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9373,\n",
       "           0.6078, -0.3176, -0.8039, -0.4902,  0.4980,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.8039, -0.5843, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.3333,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.8588,\n",
       "          -0.1059, -0.1059,  0.0510,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.0196, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4745,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.6627, -0.7020, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5922,  0.7725,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.7804,\n",
       "          -0.5059, -0.9529, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4588,\n",
       "           0.7725,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.0824, -0.4353,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -0.5451,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.7569, -0.4902, -0.4902, -0.9608, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vi trenger et nettverk\n",
    "Alle lag i PyTorch arver fra `nn.Module`. Fra [dokumentasjonen](https://pytorch.org/docs/stable/generated/torch.nn.Module.html):\n",
    "\n",
    ">Base class for all neural network modules. \n",
    ">\n",
    ">Your models should also subclass this class.\n",
    ">\n",
    ">Modules can also contain other Modules, allowing to nest them in a tree structure.\n",
    "\n",
    "Trestrukturen som nevnes er veldig nyttig. Endringer vi gjør på toppen av treet vil propageres ned til enkeltmodulene. Feks det å flytte parametrene over på en GPU.\n",
    "\n",
    "Vi husker det enkle lineære laget og tanh-funksjonen. De arver nemlig fra `nn.Module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.module.Module'>\n",
      "<class 'torch.nn.modules.module.Module'>\n"
     ]
    }
   ],
   "source": [
    "print(layer.__class__.__base__)\n",
    "print(tanh.__class__.__base__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nettverket vi lager inneholder tre lag:\n",
    "1. `layer1` tar inn et bilde med 28 $\\times$ 28 piksler flatet ut til en vektor med 784 features. Denne transformeres til en vektor med et antall features vi velger å være 200.\n",
    "2. `layer2` tar inn en vektor med 200 features og produserer en vektor med 42 features.\n",
    "3. `layer3` tar inn en vektor med 42 features og produserer en vektor med samme antall features som antallet siffer vi ønsker å skille mellom.\n",
    "\n",
    "Mellom hvert lag bruker vi `Tanh` som aktiveringsfunksjon.\n",
    "\n",
    "Modellen vår implementerer to metoder. Metoden `logits` gir unnormaliserte verdier og vil brukes under trening. Metoden `forward` bruker `softmax` til å normalisere output fra `logits`, og tas i bruk under _inference_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer1): Linear(in_features=784, out_features=200, bias=True)\n",
       "  (layer2): Linear(in_features=200, out_features=42, bias=True)\n",
       "  (layer3): Linear(in_features=42, out_features=10, bias=True)\n",
       "  (tanh): Tanh()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features=1*28*28, out_features=200) # Input features are the number of pixels, output features is arbitrary\n",
    "        self.layer2 = nn.Linear(in_features=200, out_features=42) # Arbitrary number of input- and output-features\n",
    "        self.layer3 = nn.Linear(in_features=42, out_features=10) # 10 digits to differentiate between\n",
    "\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax(dim=1) # Softmax will be computed for each batch element separately \n",
    "\n",
    "    def logits(self, data):\n",
    "        # Flatten the tensor from shape (batch_size, 1, 28, 28) to shape (batch_size, 1 * 28 * 28)\n",
    "        flattened_data = torch.flatten(data, start_dim=1, end_dim=-1) \n",
    "\n",
    "        out = self.layer1(flattened_data) # (batch_size, 784) -> (batch_size, 200)\n",
    "        out = self.tanh(out)\n",
    "\n",
    "        out = self.layer2(out) # (batch_size, 200) -> (batch_size, 42)\n",
    "        out = self.tanh(out)\n",
    "\n",
    "        out = self.layer3(out) # (batch_size, 42) -> (batch_size, 10)\n",
    "        return out # Unnormalized data (logits)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        logits = self.logits(data)\n",
    "        return self.softmax(logits) # Normalized data\n",
    "    \n",
    "model = Model() # Initialize model\n",
    "model.to(device) # Move model to GPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 165872\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\") # .numel() returns the number of elements in a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi tester modellen på sifferet vi visualiserte tidligere. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution over digits: tensor([[0.1064, 0.1206, 0.0976, 0.0882, 0.0922, 0.0935, 0.1064, 0.0957, 0.1075,\n",
      "         0.0920]], device='cuda:0')\n",
      "\n",
      "The untrained model predicts the digit to be 1, but the correct label is 6\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient calculation for inference\n",
    "    out = model.forward(data_sample.unsqueeze(0).to(device))\n",
    "print(f\"Distribution over digits: {out}\\n\")\n",
    "print(f\"The untrained model predicts the digit to be {out.argmax()}, but the correct label is {label_sample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trening\n",
    "Vi ser fra resultatene at modellen ikke er i stand til å avgjøre hvilket siffer inputten var. \n",
    "\n",
    "Vi har modellen og datasettet. Da er det to viktige ting som mangler for å kunne trene modellen. \n",
    "- **En loss-funksjon som definerer målet**\n",
    "    - Vi ønsker at modellen skal gi høyest sannsynlighet på det rette sifret.\n",
    "    \n",
    "- **En algoritme som utfører gradient descent, altså selve maskinlæringen**   \n",
    "    - Denne algoritmen skal ta utgangspunkt i losset for å forbedre parametrene.\n",
    "    - Disse er implementert i PyTorch gjennom `torch.optim`.\n",
    "    - Mer utfyllende detaljer om gradient descent finner du i `bonus_gradients.ipynb`.\n",
    "\n",
    "Loss-funksjoner sammenlikner en prediksjon mot en fasit, og gjør det mulig å måle hvor gode svarene er fra nettverket mot datasettet.  \n",
    "Den enkleste er _Mean Squared Error (MSE)_, som kalkulerer gjennomsnittlig kvadrert avvik mellom tilsvarende elementer i hver tensor på tvers av en batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(6.5000)\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([0, 1])\n",
    "b = torch.Tensor([0, 1])\n",
    "loss = F.mse_loss(a, b) # Average of [(0 - 0)^2, (1 - 1)^2] = 0\n",
    "print(loss)\n",
    "\n",
    "a = torch.Tensor([0, 1])\n",
    "b = torch.Tensor([2, 4])\n",
    "loss = F.mse_loss(a, b) # Average of [(0 - 2)^2, (1 - 4)^2] = Averge of [4, 9] = 6.5\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Som loss-funksjon skal vi heller bruke [`nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html). Den sammenlikner to sannsynlighetsfordelinger. Matematikken bak er ikke så viktig.\n",
    "\n",
    "Til gradient descent bruker vi Adam, som står for _Adaptive Moment Estimation_. Også her er ikke matematikken viktig for nå.  \n",
    "Vi spesifiserer en learning rate som forteller algoritmen hvor store endringer som gjøres på vektene ved hvert oppdateringssteg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1875/1875 [00:08<00:00, 213.61batch/s]\n",
      "Epoch 1: 100%|██████████| 1875/1875 [00:08<00:00, 218.46batch/s]\n",
      "Epoch 2: 100%|██████████| 1875/1875 [00:08<00:00, 208.83batch/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm # Progress bar\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}\", unit=\"batch\")\n",
    "        for i, (data, targets) in enumerate(progress_bar): \n",
    "            data = data.to(device) # Move data to GPU\n",
    "            targets = targets.to(device) # Move target values to GPU\n",
    "            pred = model.logits(data) # Query model for predictions\n",
    "            loss = loss_fn(pred, targets)\n",
    "            \n",
    "            loss.backward() # Calculate gradients for all parameters\n",
    "            optimizer.step() # Uses the calculated gradients on the registered parameters to perform an update\n",
    "            optimizer.zero_grad() # Remove the gradients\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing av modellen\n",
    "Vi regner ut nøyaktigheten til modellen på et datasett som ikke er observert under trening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model on the test set is 0.9541999697685242\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=32)\n",
    "\n",
    "with torch.no_grad(): # Disable gradient calculation for inference\n",
    "    correct = 0\n",
    "    for data, targets in test_loader:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        pred = model.forward(data)\n",
    "        correct += torch.sum(pred.argmax(dim=1) == targets) # Count number of correct predictions for this batch\n",
    "    accuracy = correct/len(test_dataset)\n",
    "\n",
    "print(f\"The accuracy of the model on the test set is {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi tester også på sifferet vi tidligere erfarte at modellen tok feil på. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.1942e-03, 3.8494e-05, 1.3825e-03, 3.6757e-04, 8.1013e-04, 2.1101e-02,\n",
      "         9.6070e-01, 6.0615e-07, 1.1384e-02, 1.9921e-05]], device='cuda:0')\n",
      "The trained model predicts the digit to be 6 with a probability of 0.960701584815979\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKgAAACoCAAAAABRIPpoAAADXklEQVR4Ae2az4tOURjHX/IzlMaKWdqwtBTZTMJkg2xYyVJZYbLxByhZWNhgIwtFFkqahZKJyFIsLCghLNAgIdTnWbz3zn2fe8859yRn+lp877nf8zznnvN5OnN/eAcD/RMBERABERABERABERABEZg/BBb8m6WMc5kN6A10JWqXv097C+rJQq/jf/M10dwVEdHcRBflHnDueFMY29Cdlc4/tKta6RzRVOlHQOlliWgvfCOSiyGa7V6/GAr2R2QH7RPoJnQJ6slnOo6hl5ygYohqok4Fk20RTUbnJGbY9WsZ+gJavZs7VxxhP8DbOqJnaKn0QxZ5WiKah+NwlGKI9nrCP86Cm0/vQw5hrfMBYcUQ1UQDqhkVIqJRuAKCo3f9GIMeQe2dfXnAZSxklsMkam3zn9ihVVX6VjwJnSKaAK01pRiiEU/4tru/tK672XkT6zt6Fn3YDApwiiGqiQZUMypERKNwBQRH3+sDxhzYe/plQk2/haS1xqj0rXgSOkU0AVprSjFEO3b9UlZ5Ej3QuuKP9L5A96Lvnfh1+F9R+3rvBNbsYohqorW6ZTgR0QwQa0N0POFPEDxdS5l78hLjMPoI3Y96co6OGfQq+gG9hXqi0ntkUn0RTSXn5RVDtNeut3f83UBYj06i+zwsjm+73r4QXndiiiGqiToVTLZFNBmdk9ix620/jjnJv/HfoqvRFWiazJK2C7UvA9VxVPoqjRxtEc1BsTpGMUQ73uvXsCj73Wx1fda2VY43O5KcVWQtc3KLIaqJOhVMtkU0GZ2TKKIOmGRbRJPROYki6oBJtjvu9bHj/iDhKXoavYtuRE+h9ls+mjV5x5k959c6OFHpm0z6OSLaj18zuxiiHbv+GksL/zpn/y9/hSx78j9Ke6qJqOHYL/kfN3wziiGqiToVTLZFNBmdk9jxNW+CtGknOZf9jIH2oM+dQVV6B0yyLaLJ6JzEYoh23Os/sb7XaK6vdobsDYeDqH2x/2kdjhZDVBN1Kphsi2gyOiex415vWds5XET77/0zjHMHvY2GiEofQikmRkRjaIXEFkM0aNfbijdzmAlZfiXmFe1DFece7V8VJ6RZDFFNNKScMTEiGkNLsSIgAiIgAiIgAiIgAiIgAiIgAiIgAiIgAiIgAvOJwF/mwEqClQcOLAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=168x168>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient calculation for inference\n",
    "    out = model.forward(data_sample.unsqueeze(0).to(device))\n",
    "print(out)\n",
    "print(f\"The trained model predicts the digit to be {out.argmax()} with a probability of {out.max()}\")\n",
    "visualize(data_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

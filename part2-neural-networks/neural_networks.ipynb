{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    import torch\n",
    "    from IPython.core.display import HTML\n",
    "    from IPython.display import display\n",
    "    import os\n",
    "    print(\"Running in Google Colab\")\n",
    "    if not torch.cuda.is_available():\n",
    "        display(HTML(\"\"\"<div style=\"background-color: red; font-weight: bold; color: white;\">You have not activated a GPU in Google Colab. Follow the instructions in the <code style=\"color: white;\">README</code></div>\"\"\"))\n",
    "    print(\"Installing requirements\")\n",
    "    requirements_url = \"https://raw.githubusercontent.com/willdalh/ml-course/main/requirements.txt\"\n",
    "    if not os.path.exists('requirements.txt'):\n",
    "        !wget {requirements_url}\n",
    "    %pip install --user -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nevrale nettverk med PyTorch\n",
    "Nevrale nettverk har tilsynelatende komplekse strukturer. Likevel består de av flere enkle og isolerte komponenter. Disse finner man i `torch.nn`. \n",
    "\n",
    "De fleste komponentene blir et _lag_ i nettverket, men det finnes komponenter som anvendes på eksisterende lag (feks aktiveringsfunksjoner). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Den enkleste komponenten man finner i nevrale nettverk er lineære lag. Matematisk gjør den en lineær transformasjon fra et vektorrom til et annet. Feks kan det lineære laget ta inn en vektor med 3 features, og outputte en vektor med 2 features:\n",
    "\n",
    "\n",
    "\n",
    "<div >\n",
    "<img src=\"../res/nn_3in_2out.png\" width=\"30%\" alt=\"SVG Image\"/>\n",
    "</div>\n",
    "\n",
    "Hver node representerer en numerisk verdi. En kobling mellom to noder indikerer en vekt, som ganges sammen med verdien fra en node til venstre og summeres sammen med alle de andre koblingene som går inn i en node til høyre. Vi kommer til å erfare at dette utføres som én matriseoperasjon.\n",
    "\n",
    "\n",
    "I PyTorch lager vi lineære lag gjennom `torch.nn.Linear`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=3, out_features=2, bias=True)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.Linear(in_features=3, out_features=2) # Construct layer\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vector: tensor([[1., 1., 1.]])\n",
      "Output vector: tensor([[0.7027, 0.5688]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "data = torch.Tensor([[1, 1, 1]])\n",
    "print(f\"Input vector: {data}\")\n",
    "output = layer(data) # Feed data into layer\n",
    "print(f\"Output vector: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hva er det egentlig som har skjedd her? Vektoren, som består av 3 enere, har blitt til transformert til en vektor med 2 tall. Vi studerer _vektene_ til det lineære laget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2212,  0.2245, -0.2941],\n",
      "        [-0.3738,  0.1406,  0.4805]], requires_grad=True)\n",
      "Weight shape: torch.Size([2, 3])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(layer.weight)\n",
    "print(f\"Weight shape: {layer.weight.shape}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrisen viser tallene som tilknyttes hver linje som trekkes mellom nodene i figuren over. \n",
    "\n",
    "I tillegg til vektene, har lineære lag et konstantledd. Denne adderes på resultatet fra matriseoperasjonen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.5512, 0.3214], requires_grad=True)\n",
      "Bias shape: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print(layer.bias)\n",
    "print(f\"Bias shape: {layer.bias.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Når man sender input-vektoren inn skjer følgende operasjon (hvor `@` er matrisemultiplikasjon):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data @ layer.weight.T + layer.bias is similar to layer(data): True\n"
     ]
    }
   ],
   "source": [
    "data @ layer.weight.T + layer.bias\n",
    "print(f\"data @ layer.weight.T + layer.bias is similar to layer(data): {(data @ layer.weight.T + layer.bias == layer(data)).all()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi ser fra resultatet over at det stemmer.\n",
    "\n",
    "\n",
    "Vektene og biaset utgjør til sammen **parametrene** for dette lineære laget, og er verdiene som endres når man trener nettverket. Hvordan disse er strukturert og brukes varierer avhengig av typen lag. Til denne introduksjon holder vi oss derimot til lineære lag, men sjekk ut `bonus_convnet.ipynb` for å se hvordan man bruker konvolusjonelle lag. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aktiveringsfunksjoner\n",
    "\n",
    "Det lineære laget utfører en lineær operasjon. Fleksibiliteten av nevrale nettverk kommer derimot av såkalte _aktiveringsfunksjoner_ som utfører ikke-lineære operasjoner på data. Disse inneholder **vanligvis ikke** trenbare parametre. De enkleste opererer på hvert element av en tensor individuelt, som feks Tanh. Av denne grunn modifiseres ikke _shapen_ til tensoren. Vi ser på et en-dimensjonalt-case for å visualisere det enkelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt # Library for visualization\n",
    "tanh = nn.Tanh()\n",
    "assert not hasattr(tanh, \"weight\") # No learnable weights\n",
    "\n",
    "data = torch.linspace(start=-6, end=6, steps=100) # Vector with 100 elements increasing from -6 to 6 \n",
    "output = tanh(data)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "ax.plot(data, output)\n",
    "ax.set_xlabel(\"Input data\")\n",
    "ax.set_ylabel(\"Tanh Output\")\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En annen viktig er `nn.Softmax`, og brukes til å transformere en vektor til elementer som summeres til 1. \n",
    "\n",
    "Dette gjør den litt annerledes enn Tanh, siden vi må spesifisere en av shape-dimensjonene som skal summeres til 1.\n",
    "\n",
    "Den gjør seg svært godt som siste lag i et nettverk vi ønsker skal modellere en sannsynlighetsfordeling (Total sannsynlighet av alle utfallene av en stokastisk variabel skal være 1). Den er feks brukt som siste lag i ChatGPT, siden språkmodeller lærer seg en betinget sannsynlighetsfordeling over ord gitt tidligere tekst.\n",
    "\n",
    "For denne anledningen tar vi også i bruk `nn.functional`, som er et delbibliotek som tilbyr komponentene tilstandsfrie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "tensor([[6., 6.],\n",
      "        [3., 4.],\n",
      "        [4., 6.]])\n",
      "Transformed data:\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.2689, 0.7311],\n",
      "        [0.1192, 0.8808]])\n",
      "Summing individual batch elements:\n",
      "tensor([1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "data = torch.randint(low=1, high=10, size=(3, 2)).float()\n",
    "print(f\"Original data:\\n{data}\")\n",
    "data = F.softmax(data, dim=1)\n",
    "print(f\"Transformed data:\\n{data}\")\n",
    "print(f\"Summing individual batch elements:\\n{data.sum(dim=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifisering av sifre\n",
    "Vi skal sette opp et nevralt nettverk som er i stand til å klassifisere sifre. Til det trenger vi det lett tilgjengelige MNIST-datasettet. Dette lastes ned gjennom torchvision-biblioteket. Torchvision-biblioteket er et hjelpebibliotek som tilbyr verktøy for Computer Vision-oppgaver. \n",
    "\n",
    "Datasett kommer vanligvis i et rå-format, og må behandles for å tilpasse det oppgaven vi skal gjøre. I dette tilfellet får vi PNG-bilder som må gjøres om til tensorer. Vi normaliserer også bildene for å få [bedre resultater](https://developers.google.com/machine-learning/data-prep/transform/normalization). Behandlingen gjøres med `torchvision.transforms`-biblioteket. \n",
    "\n",
    "Datasettet lagres i roten av prosjektet i mappen `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Pipeline of processing operations\n",
    "image_processing = transforms.Compose([\n",
    "    transforms.ToTensor(), # Cast into torch.Tensor\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Pixel-values will range in [-1, 1]\n",
    "])\n",
    "\n",
    "train_dataset = MNIST(root='../data', train=True, transform=image_processing, download=True)\n",
    "test_dataset = MNIST(root='../data', train=False, transform=image_processing, download=True) # Test data for later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I maskinlæring trener man flere epoker (iterasjoner) på samme datasettet. \n",
    "\n",
    "Hver epoke inneholder igjen flere iterasjoner som består av å oppdatere vektene på et lite subset av datasettet. Man kaller dette for en batch. Vi lager en `DataLoader` som batcher dataen for oss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data batch: torch.Size([32, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32) # Iterable that provides 32 data samples each iteration\n",
    "\n",
    "data, labels = next(iter(train_loader)) # Retrieve a batch of data samples and labels for inspection purposes\n",
    "print(f\"Shape of data batch: {data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensoren inneholder 32 eksemplarer, 1 fargekanal (grayscale), 28 piksler i høyden, og 28 piksler i bredden.\n",
    "Vi kan visualisere et tilfeldig eksemplar fra datasettet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42); # Set random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shown below is the digit 6, with shape torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKgAAACoCAAAAABRIPpoAAADXklEQVR4Ae2az4tOURjHX/IzlMaKWdqwtBTZTMJkg2xYyVJZYbLxByhZWNhgIwtFFkqahZKJyFIsLCghLNAgIdTnWbz3zn2fe8859yRn+lp877nf8zznnvN5OnN/eAcD/RMBERABERABERABERABEZg/BBb8m6WMc5kN6A10JWqXv097C+rJQq/jf/M10dwVEdHcRBflHnDueFMY29Cdlc4/tKta6RzRVOlHQOlliWgvfCOSiyGa7V6/GAr2R2QH7RPoJnQJ6slnOo6hl5ygYohqok4Fk20RTUbnJGbY9WsZ+gJavZs7VxxhP8DbOqJnaKn0QxZ5WiKah+NwlGKI9nrCP86Cm0/vQw5hrfMBYcUQ1UQDqhkVIqJRuAKCo3f9GIMeQe2dfXnAZSxklsMkam3zn9ihVVX6VjwJnSKaAK01pRiiEU/4tru/tK672XkT6zt6Fn3YDApwiiGqiQZUMypERKNwBQRH3+sDxhzYe/plQk2/haS1xqj0rXgSOkU0AVprSjFEO3b9UlZ5Ej3QuuKP9L5A96Lvnfh1+F9R+3rvBNbsYohqorW6ZTgR0QwQa0N0POFPEDxdS5l78hLjMPoI3Y96co6OGfQq+gG9hXqi0ntkUn0RTSXn5RVDtNeut3f83UBYj06i+zwsjm+73r4QXndiiiGqiToVTLZFNBmdk9ix620/jjnJv/HfoqvRFWiazJK2C7UvA9VxVPoqjRxtEc1BsTpGMUQ73uvXsCj73Wx1fda2VY43O5KcVWQtc3KLIaqJOhVMtkU0GZ2TKKIOmGRbRJPROYki6oBJtjvu9bHj/iDhKXoavYtuRE+h9ls+mjV5x5k959c6OFHpm0z6OSLaj18zuxiiHbv+GksL/zpn/y9/hSx78j9Ke6qJqOHYL/kfN3wziiGqiToVTLZFNBmdk9jxNW+CtGknOZf9jIH2oM+dQVV6B0yyLaLJ6JzEYoh23Os/sb7XaK6vdobsDYeDqH2x/2kdjhZDVBN1Kphsi2gyOiex415vWds5XET77/0zjHMHvY2GiEofQikmRkRjaIXEFkM0aNfbijdzmAlZfiXmFe1DFece7V8VJ6RZDFFNNKScMTEiGkNLsSIgAiIgAiIgAiIgAiIgAiIgAiIgAiIgAiIgAvOJwF/mwEqClQcOLAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=168x168>"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.visualize import visualize\n",
    "\n",
    "# Get a random sample from the training dataset\n",
    "rand_index = torch.randint(0, len(train_dataset), (1,)).item()\n",
    "data_sample, label_sample = train_dataset[rand_index]\n",
    "\n",
    "print(f\"Shown below is the digit {label_sample}, with shape {data_sample.shape}\")\n",
    "visualize(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Og tensoren i seg selv ser slik ut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -0.7804, -0.4745,  0.8980,  0.9922,\n",
       "           1.0000,  0.5451, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -0.0667,  0.4196,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.5373, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9529, -0.9216,\n",
       "          -0.3725,  0.5529,  0.9373,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.8667, -0.2314, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -0.7961,  0.4196,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.5373, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -0.0824,  0.4039,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843, -0.2863, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -0.9922, -0.8510, -0.0196,  0.9137,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.8824, -0.5373, -0.6392,\n",
       "          -0.6392, -0.9843, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -0.9216,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.3804,  0.3176, -0.5608, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -0.9216,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.5373, -0.1922, -0.9137, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9373,  0.0039,\n",
       "           0.7098,  0.9843,  0.9843,  0.9843,  0.9843,  0.8510,  0.5922,\n",
       "          -0.8196, -1.0000, -1.0000, -1.0000, -1.0000, -0.7882, -0.8745,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4745,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.7333, -0.4980, -0.9137,\n",
       "          -0.2549, -0.2549, -0.2549, -0.2549, -0.2549,  0.8980,  0.4275,\n",
       "          -0.2549, -0.4196, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4745,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.8902, -0.5137, -0.2471,  0.3333,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.8196, -0.3490, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.8431,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9686,  0.7725,  0.8980,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.8824, -0.5451, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.9922,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843, -0.4902, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.9922,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843, -0.4902, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.9922,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9373,\n",
       "           0.6078, -0.3176, -0.8039, -0.4902,  0.4980,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.8039, -0.5843, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.3333,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.8588,\n",
       "          -0.1059, -0.1059,  0.0510,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.0196, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4745,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.6627, -0.7020, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5922,  0.7725,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.7804,\n",
       "          -0.5059, -0.9529, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4588,\n",
       "           0.7725,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.0824, -0.4353,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -0.5451,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "           0.9843,  0.9843,  0.7569, -0.4902, -0.4902, -0.9608, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vi trenger et nettverk\n",
    "Alle lag i PyTorch arver fra `nn.Module`. Fra [dokumentasjonen](https://pytorch.org/docs/stable/generated/torch.nn.Module.html):\n",
    "\n",
    ">Base class for all neural network modules. \n",
    ">\n",
    ">Your models should also subclass this class.\n",
    ">\n",
    ">Modules can also contain other Modules, allowing to nest them in a tree structure.\n",
    "\n",
    "Trestrukturen som nevnes er veldig nyttig. Endringer vi gjør på toppen av treet vil propageres ned til enkeltmodulene. Feks det å flytte parametrene over på en GPU.\n",
    "\n",
    "Vi husker det enkle lineære laget og tanh-funksjonen. De arver nemlig fra `nn.Module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.module.Module'>\n",
      "<class 'torch.nn.modules.module.Module'>\n"
     ]
    }
   ],
   "source": [
    "print(layer.__class__.__base__)\n",
    "print(tanh.__class__.__base__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nettverket vi lager inneholder tre lag:\n",
    "1. `layer1` tar inn et bilde med 28 $\\times$ 28 piksler flatet ut til en vektor med 784 features. Denne transformeres til en vektor med et antall features vi velger å være 200.\n",
    "2. `layer2` tar inn en vektor med 200 features og produserer en vektor med 42 features.\n",
    "3. `layer3` tar inn en vektor med 42 features og produserer en vektor med samme antall features som antallet siffer vi ønsker å skille mellom.\n",
    "\n",
    "Mellom hvert lag bruker vi `Tanh` som aktiveringsfunksjon.\n",
    "\n",
    "Modellen vår implementerer to metoder. Metoden `logits` gir unnormaliserte verdier og vil brukes under trening. Metoden `forward` bruker `softmax` til å normalisere output fra `logits`, og tas i bruk under _inference_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer1): Linear(in_features=784, out_features=200, bias=True)\n",
       "  (layer2): Linear(in_features=200, out_features=42, bias=True)\n",
       "  (layer3): Linear(in_features=42, out_features=10, bias=True)\n",
       "  (tanh): Tanh()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features=1*28*28, out_features=200) # Input features are the number of pixels, output features is arbitrary\n",
    "        self.layer2 = nn.Linear(in_features=200, out_features=42) # Arbitrary values\n",
    "        self.layer3 = nn.Linear(in_features=42, out_features=10) # 10 digits to differentiate between\n",
    "\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax(dim=1) # Softmax will be computed for each batch element separately \n",
    "\n",
    "    def logits(self, data):\n",
    "        # Flatten the tensor from shape (batch_size, 1, 28, 28) to shape (batch_size, 1 * 28 * 28)\n",
    "        flattened_data = torch.flatten(data, start_dim=1, end_dim=-1) \n",
    "\n",
    "        out = self.layer1(flattened_data)\n",
    "        out = self.tanh(out)\n",
    "\n",
    "        out = self.layer2(out)\n",
    "        out = self.tanh(out)\n",
    "\n",
    "        out = self.layer3(out)\n",
    "        return out\n",
    "    \n",
    "    def forward(self, data):\n",
    "        logits = self.logits(data)\n",
    "        return self.softmax(logits)\n",
    "    \n",
    "model = Model() # Initialize model\n",
    "model.to(device) # Move model to GPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 165872\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\") # .numel() returns the number of elements in a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi tester modellen på sifferet vi visualiserte tidligere. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution over digits: tensor([[4.1942e-03, 3.8494e-05, 1.3825e-03, 3.6757e-04, 8.1013e-04, 2.1101e-02,\n",
      "         9.6070e-01, 6.0615e-07, 1.1384e-02, 1.9921e-05]], device='cuda:0')\n",
      "\n",
      "The untrained model predicts the digit to be 6, but the correct label is 6\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient calculation for inference\n",
    "    out = model.forward(data_sample.unsqueeze(0).to(device))\n",
    "print(f\"Distribution over digits: {out}\\n\")\n",
    "print(f\"The untrained model predicts the digit to be {out.argmax()}, but the correct label is {label_sample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trening\n",
    "Vi ser fra resultatene at modellen ikke er i stand til å avgjøre hvilket siffer inputten var. \n",
    "\n",
    "Vi har modellen og datasettet. Da er det to viktige ting som mangler for å kunne trene modellen. \n",
    "- **En loss-funksjon som definerer målet**\n",
    "    - Vi ønsker at modellen skal gi høyest sannsynlighet på det rette sifret.\n",
    "    \n",
    "- **En algoritme som utfører gradient descent, altså selve maskinlæringen**   \n",
    "    - Denne algoritmen skal ta utgangspunkt i losset for å forbedre parametrene.\n",
    "    - Disse er implementert i PyTorch gjennom `torch.optim`.\n",
    "    - Utfyllende detaljer om gradient descent finner du i `bonus_gradients.ipynb`.\n",
    "\n",
    "Loss-funksjoner sammenlikner en prediksjon mot en fasit, og gjør det mulig å måle hvor gode svarene er fra nettverket mot datasettet.  \n",
    "Den enkleste er _Mean Squared Error (MSE)_, som kalkulerer gjennomsnittlig kvadrert avvik mellom tilsvarende elementer i hver tensor på tvers av en batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(6.5000)\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([0, 1])\n",
    "b = torch.Tensor([0, 1])\n",
    "loss = F.mse_loss(a, b) # Average of [(0 - 0)^2, (1 - 1)^2] = 0\n",
    "print(loss)\n",
    "\n",
    "a = torch.Tensor([0, 1])\n",
    "b = torch.Tensor([2, 4])\n",
    "loss = F.mse_loss(a, b) # Average of [(0 - 2)^2, (1 - 4)^2] = Averge of [4, 9] = 6.5\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Til loss-funksjonen bruker vi [`nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html). Den sammenlikner to sannsynlighetsfordelinger. Matematikken bak er ikke så viktig.\n",
    "\n",
    "Til gradient descent bruker vi Adam, som står for _Adaptive Moment Estimation_. Også her er ikke matematikken viktig for nå.  \n",
    "Vi spesifiserer en learning rate som forteller algoritmen hvor store endringer som gjøres på vektene ved hvert oppdateringssteg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1875/1875 [00:07<00:00, 266.42batch/s]\n",
      "Epoch 1: 100%|██████████| 1875/1875 [00:06<00:00, 281.61batch/s]\n",
      "Epoch 2: 100%|██████████| 1875/1875 [00:06<00:00, 286.78batch/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm # Progress bar\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    with tqdm(train_loader, unit=\"batch\") as pbar:\n",
    "        pbar.set_description(f\"Epoch {epoch}\")\n",
    "        for i, (data, labels) in enumerate(pbar):\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pred = model.logits(data) # Query model for predictions\n",
    "            loss = loss_fn(pred, labels)\n",
    "            \n",
    "            loss.backward() # Calculate gradients for all parameters\n",
    "            optimizer.step() # Uses the calculated gradients on the registered parameters to perform an update\n",
    "            optimizer.zero_grad() # Remove the gradients\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing av modellen\n",
    "Vi regner ut nøyaktigheten til modellen på et datasett som ikke er observert under trening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model on the test set is 0.9541999697685242\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=32)\n",
    "\n",
    "with torch.no_grad(): # Disable gradient calculation for inference\n",
    "    correct = 0\n",
    "    for data, labels in test_loader:\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        pred = model.forward(data)\n",
    "        correct += torch.sum(pred.argmax(dim=1) == labels) # Count number of correct predictions for this batch\n",
    "    accuracy = correct/len(test_dataset)\n",
    "\n",
    "print(f\"The accuracy of the model on the test set is {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi tester også på sifferet vi tidligere erfarte at modellen tok feil på. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.1942e-03, 3.8494e-05, 1.3825e-03, 3.6757e-04, 8.1013e-04, 2.1101e-02,\n",
      "         9.6070e-01, 6.0615e-07, 1.1384e-02, 1.9921e-05]], device='cuda:0')\n",
      "The trained model predicts the digit to be 6 with a probability of 0.960701584815979\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKgAAACoCAAAAABRIPpoAAADXklEQVR4Ae2az4tOURjHX/IzlMaKWdqwtBTZTMJkg2xYyVJZYbLxByhZWNhgIwtFFkqahZKJyFIsLCghLNAgIdTnWbz3zn2fe8859yRn+lp877nf8zznnvN5OnN/eAcD/RMBERABERABERABERABEZg/BBb8m6WMc5kN6A10JWqXv097C+rJQq/jf/M10dwVEdHcRBflHnDueFMY29Cdlc4/tKta6RzRVOlHQOlliWgvfCOSiyGa7V6/GAr2R2QH7RPoJnQJ6slnOo6hl5ygYohqok4Fk20RTUbnJGbY9WsZ+gJavZs7VxxhP8DbOqJnaKn0QxZ5WiKah+NwlGKI9nrCP86Cm0/vQw5hrfMBYcUQ1UQDqhkVIqJRuAKCo3f9GIMeQe2dfXnAZSxklsMkam3zn9ihVVX6VjwJnSKaAK01pRiiEU/4tru/tK672XkT6zt6Fn3YDApwiiGqiQZUMypERKNwBQRH3+sDxhzYe/plQk2/haS1xqj0rXgSOkU0AVprSjFEO3b9UlZ5Ej3QuuKP9L5A96Lvnfh1+F9R+3rvBNbsYohqorW6ZTgR0QwQa0N0POFPEDxdS5l78hLjMPoI3Y96co6OGfQq+gG9hXqi0ntkUn0RTSXn5RVDtNeut3f83UBYj06i+zwsjm+73r4QXndiiiGqiToVTLZFNBmdk9ix620/jjnJv/HfoqvRFWiazJK2C7UvA9VxVPoqjRxtEc1BsTpGMUQ73uvXsCj73Wx1fda2VY43O5KcVWQtc3KLIaqJOhVMtkU0GZ2TKKIOmGRbRJPROYki6oBJtjvu9bHj/iDhKXoavYtuRE+h9ls+mjV5x5k959c6OFHpm0z6OSLaj18zuxiiHbv+GksL/zpn/y9/hSx78j9Ke6qJqOHYL/kfN3wziiGqiToVTLZFNBmdk9jxNW+CtGknOZf9jIH2oM+dQVV6B0yyLaLJ6JzEYoh23Os/sb7XaK6vdobsDYeDqH2x/2kdjhZDVBN1Kphsi2gyOiex415vWds5XET77/0zjHMHvY2GiEofQikmRkRjaIXEFkM0aNfbijdzmAlZfiXmFe1DFece7V8VJ6RZDFFNNKScMTEiGkNLsSIgAiIgAiIgAiIgAiIgAiIgAiIgAiIgAiIgAvOJwF/mwEqClQcOLAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=168x168>"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient calculation for inference\n",
    "    out = model.forward(data_sample.unsqueeze(0).to(device))\n",
    "print(out)\n",
    "print(f\"The trained model predicts the digit to be {out.argmax()} with a probability of {out.max()}\")\n",
    "visualize(data_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

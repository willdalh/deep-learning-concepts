{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    import torch\n",
    "    from IPython.core.display import HTML\n",
    "    from IPython.display import display \n",
    "    import os\n",
    "    print(\"Running in Google Colab\")\n",
    "    if not torch.cuda.is_available():\n",
    "        display(HTML(\"\"\"<div style=\"background-color: red; font-weight: bold; color: white;\">You have not activated a GPU in Google Colab. Follow the instructions in the <code style=\"color: white;\">README</code></div>\"\"\"))\n",
    "    print(\"Installing requirements\")\n",
    "    requirements_url = \"https://raw.githubusercontent.com/willdalh/ml-course/main/requirements.txt\"\n",
    "    if not os.path.exists('requirements.txt'):\n",
    "        !wget {requirements_url}\n",
    "    %pip install --user -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing (NLP)\n",
    "Spr친kteknologi (NLP p친 engelsk) fikk en boost etter at [Transformer-arkitekturen](https://arxiv.org/abs/1706.03762) ble introdusert i 2017. Denne arkitekturen danner grunnlaget for de aller fleste tjenestene som kombinerer AI og spr친k idag, der ChatGPT er et godt eksempel. \n",
    "\n",
    "Siden da har [Hugging Face](huggingface.co) dukket opp som plattform som fors칮ker 친 tilgjengeliggj칮re datasett, implementasjoner og erfaringer innen NLP. Av den grunn vil denne notebooken ta i bruk bibliotekene som tilbys fra dem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fyll inn det manglende ordet\n",
    "Modellen som f칮rst demonstrerte styrken til Transformere, er BERT, som st친r for _Bidirectional Encoder Representations from Transformers_. Den lager alts친 vektorrepresentasjoner av ord ved 친 se p친 b친de ordene som kom f칮r, samt de etterf칮lgende ordene i en setning. Nasjonalbiblioteket har trent en norsk versjon av denne, som vi finner p친 Hugging Face. \n",
    "\n",
    "Vi setter opp en unmasker som tar i bruk en BERT-modell i bunnen for 친 beregne hvilket ord som mangler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a253f974633d42a3b6716a9c63c2def3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02fe96f5dec8464aa8dbfc51e8a39b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 游녤v4.50游녣 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66d686fcb714f81a9e77bc137c7b649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f12172bf35e4a5f8ae8afce47f065dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a7a9cdf1cc48c4b0dbb5c00aa18b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='NbAiLab/nb-bert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'journal'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = unmasker(\"I Norge brukes elektronisk [MASK] p친 sykehusene\")\n",
    "res[0]['token_str']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sammenlikne setninger\n",
    "BERT lager bare embeddinger av enkeltord, men i noen tilfeller 칮nsker vi 친 ha embeddinger for hele setninger, slik at vi kan sammenlikne dem. Til dette bruker vi en Sentence Transformer, og igjen har Nasjonalbiblioteket trent en som vi finner p친 Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50224c56eff14823a4c846e8cffdd88b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3268ace9bb44650a1adaf8fba099b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb8ad01f1384c42a503b44e0b8f7a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/9.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2fea330c554987b520554e51b00774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee00af9ba7f4a6687a0e89fed025033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/853 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e7ace5f8fa48dfb23799e318b65138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/711M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837dd3131e89434992d8767c0daa6fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/377 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24345fd96034ec79925dc28bd5f85e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aba5e888a7c46d5af6b937a1e858886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.92M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7898c3b0ac04d8ab4afa66e2df473d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b065e8e7c1dc47c5b85739ba0ae1f900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('NbAiLab/nb-sbert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "anchor = \"Jeg liker 친 spise iskrem\"\n",
    "anchor_embedding = model.encode(anchor, convert_to_tensor=True)\n",
    "print(anchor_embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi ser at setningen er er blitt gjort om til en vektor med 768 tall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 768])\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"Is er veldig godt\", \"Norske sykehus bruker elektronisk pasientjournal\"]\n",
    "sentence_embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "print(sentence_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi skal n친 sammenlikne embeddingene av de to setningene med anker-setningen. Embeddingene er vektorer/punkter, og det er flere m친ter 친 gj칮re dette p친. Vi bruker cosinus-likhet, som er cosinus av vinkelen som spennes mellom to vektorer. Men man kunne ogs친 brukt Euklidsk avstand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities with the sentence 'Jeg liker 친 spise iskrem':\n",
      "Is er veldig godt: 0.669\n",
      "Norske sykehus bruker elektronisk pasientjournal: 0.069\n"
     ]
    }
   ],
   "source": [
    "similarities_with_anchor = []\n",
    "for emb in sentence_embeddings:\n",
    "    cos_sim = util.cos_sim(anchor_embedding, emb).item()\n",
    "    similarities_with_anchor.append(cos_sim)\n",
    "\n",
    "print(f\"Similarities with the sentence '{anchor}':\")\n",
    "for i, sentence in enumerate(sentences):\n",
    "    print(f\"{sentence}: {similarities_with_anchor[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likhetss칮k i database\n",
    "Vi ser at embeddinger fungerer bra for 친 sammenlikne konteksten mellom to setninger, uten at ordene som brukes trenger 친 v칝re helt like. Av denne grunn har det dukket opp flere tjenester som tilbyr 친 lagre embeddinger og utf칮re kjappe likhetss칮k mellom dokumenter, der eksempler er [Redis Vector Database](https://redis.io/docs/get-started/vector-database/) og [Pinecone](https://www.pinecone.io/).\n",
    "\n",
    "For 친 utforske hvordan vektordatabaser fungerer i praksis, lager vi en enkel implementasjon selv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorDatabase:\n",
    "    def __init__(self, model: SentenceTransformer):\n",
    "        self.documents = [] # list of strings\n",
    "        self.embeddings = [] # list of torch.Tensors\n",
    "        self.model = model # The SentenceTransformer model to use\n",
    "\n",
    "    def add_document(self, document: str) -> None:\n",
    "        \"\"\"\n",
    "        Add a document to the database. The document will be embedded using the model.\n",
    "\n",
    "        Args:\n",
    "            document (str): The document to add\n",
    "        \"\"\"\n",
    "        self.documents.append(document)\n",
    "        emb = self.model.encode(document, convert_to_tensor=True)\n",
    "        self.embeddings.append(emb)\n",
    "\n",
    "    def similarity_search(self, anchor_document: str, top_k: int = 3):\n",
    "        \"\"\"\n",
    "        Search for the most similar documents to the anchor document.\n",
    "\n",
    "        Args:\n",
    "            anchor_document (str): The document to search for\n",
    "            top_k (int, optional): The number of documents to return. Defaults to 3.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of tuples containing the document and the similarity score\n",
    "        \"\"\"\n",
    "        anchor_emb = self.model.encode(anchor_document, convert_to_tensor=True) # Embed the anchor document\n",
    "        similarities = []\n",
    "        for emb in self.embeddings: # Iterate all the document embeddings\n",
    "            cos_sim = util.cos_sim(anchor_emb, emb).item()\n",
    "            similarities.append(cos_sim)\n",
    "        top_k_similar_indices = torch.topk(torch.tensor(similarities), k=top_k).indices.tolist() # Get the indices of the top k most similar documents\n",
    "        res = [(self.documents[i], similarities[i]) for i in top_k_similar_indices] # Get the documents and their similarity scores\n",
    "        return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [ \n",
    "    \"P친 norske sykehus brukes det elektroniske pasientjournaler\", \n",
    "    \"Bier er viktige for pollinering av mange av v친re matvekster.\",  \n",
    "    \"Mange nordmenn elsker 친 g친 p친 ski om vinteren.\",  \n",
    "    \"Astronomi er studiet av universet og dets himmellegemer.\",\n",
    "    \"Ute i verdensrommet finnes det mange planeter og stjerner.\",\n",
    "    \"Sjokolade er en popul칝r godbit som lages fra kakaob칮nner.\",  \n",
    "    \"Fotball er en av de mest popul칝re sportene i verden.\",  \n",
    "    \"Paris er kjent for sin arkitektur, mat og mote.\",  \n",
    "    \"Elefanter er det st칮rste landdyret p친 jorden.\",  \n",
    "    \"B칮ker er en viktig kilde til kunnskap og underholdning.\",  \n",
    "    \"Musikk er en universell form for kunst som uttrykker f칮lelser og ideer.\",  \n",
    "    \"Klimaendringer er en stor utfordring for verden i dag.\",\n",
    "    \"Taco er vanlig 친 spise p친 fredager\"\n",
    "]  \n",
    "\n",
    "vector_db = VectorDatabase(model)\n",
    "for document in corpus:\n",
    "    vector_db.add_document(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Klimaendringer er en stor utfordring for verden i dag.',\n",
       "  0.5642092227935791)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_document = \"Global oppvarming 칮delegger jordkloden\"\n",
    "similar_documents = vector_db.similarity_search(anchor_document, top_k=1)\n",
    "similar_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Astronomi er studiet av universet og dets himmellegemer.',\n",
       "  0.4471147060394287),\n",
       " ('Ute i verdensrommet finnes det mange planeter og stjerner.',\n",
       "  0.4305837154388428),\n",
       " ('Musikk er en universell form for kunst som uttrykker f칮lelser og ideer.',\n",
       "  0.1297226846218109)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_sentence = \"N친r det er m칮rkt og skyfritt kan man se stjerner\"\n",
    "similar_sentences = vector_db.similarity_search(anchor_sentence, top_k=3)\n",
    "similar_sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

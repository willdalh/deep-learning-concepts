{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "import os\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print(\"Running in Google Colab, installing requirements...\")\n",
    "    # URL of the requirements file\n",
    "    requirements_url = \"https://raw.githubusercontent.com/willdalh/ml-course/main/requirements.txt\"\n",
    "\n",
    "    # Check if the requirements file already exists\n",
    "    if not os.path.exists('requirements.txt'):\n",
    "        # Download the requirements file\n",
    "        !wget {requirements_url}\n",
    "\n",
    "    # Install the requirements\n",
    "    !python -m pip install --user -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing (NLP)\n",
    "Språkteknologi (NLP på engelsk) fikk en boost etter at [Transformer-arkitekturen](https://arxiv.org/abs/1706.03762) ble introdusert i 2017. Denne arkitekturen danner grunnlaget for de aller fleste tjenestene som kombinerer AI og språk idag, der ChatGPT er et godt eksempel. \n",
    "\n",
    "Siden da har [Hugging Face](huggingface.co) dukket opp som plattform som forsøker å tilgjengeliggjøre datasett, implementasjoner og erfaringer innen NLP. Av den grunn vil denne notebooken ta i bruk bibliotekene som tilbys fra dem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fyll inn det manglende ordet\n",
    "Modellen som først demonstrerte styrken til Transformere, er BERT, som står for _Bidirectional Encoder Representations from Transformers_. Den lager altså vektorrepresentasjoner av ord ved å se på både ordene som kom før, samt de etterfølgende ordene i en setning. Nasjonalbiblioteket har trent en norsk versjon av denne, som vi finner på Hugging Face. \n",
    "\n",
    "Vi setter opp en unmasker som tar i bruk en BERT-modell i bunnen for å beregne hvilket ord som mangler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94925ac8956341138decc86820d9c135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60c1e12cf1b409990b98124864a6692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b034b548ce4f8da750bb02e2b3031b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c03dcdfb714febb84b11688c0d6ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea240cec370543798ba8f8b6b6b44c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='NbAiLab/nb-bert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'journal'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = unmasker(\"I Norge brukes elektronisk [MASK] på sykehusene\")\n",
    "res[0]['token_str']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sammenlikne setninger\n",
    "BERT lager bare embeddinger av enkeltord, men i noen tilfeller ønsker vi å ha embeddinger for hele setninger, slik at vi kan sammenlikne dem. Til dette bruker vi en Sentence Transformer, og igjen har Nasjonalbiblioteket trent en som vi finner på Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0f545c40d44de4891b1278b68d289a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb905da150c74c4d912e4c3c7bc9a0fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca4231b7f99448e8c63c8c46eeb3348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/9.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de0008979bde4031bdd6356164a78a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/853 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df16eef34824af7a8e069208452b15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8884bd50b5a740af8d67926800a24997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)imilarity_evaluation_sts-dev_results.csv:   0%|          | 0.00/1.89k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff22d9fdb6bb4def8924581c3e9c4ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/711M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543e8e30a3954276806db8a3e607da3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a86f79eeb374acb845da73f2ecf13bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)milarity_evaluation_sts-test_results.csv:   0%|          | 0.00/298 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3286a214ced54d8297b43d2a1934f332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfead5aa57d94eb7b6ebaf4fe977a35c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.92M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe28bf889deb4a97845bc5d5e48edc23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/377 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f8be5f205b41da9ab355ea195a08b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd16d54257c34557adc939aa7c631ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('NbAiLab/nb-sbert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "anchor = \"Jeg liker å spise iskrem\"\n",
    "anchor_embedding = model.encode(anchor, convert_to_tensor=True)\n",
    "print(anchor_embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi ser at setningen er er blitt gjort om til en vektor med 768 tall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 768])\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"Is er veldig godt\", \"Norske sykehus bruker elektronisk pasientjournal\"]\n",
    "sentence_embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "print(sentence_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi skal nå sammenlikne embeddingene av de to setningene med anker-setningen. Embeddingene er vektorer/punkter, og det er flere måter å gjøre dette på. Vi bruker cosinus-likhet, som er cosinus av vinkelen som spennes mellom to vektorer. Men man kunne også brukt Euklidsk avstand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities with the sentence 'Jeg liker å spise iskrem':\n",
      "Is er veldig godt: 0.669\n",
      "Norske sykehus bruker elektronisk pasientjournal: 0.069\n"
     ]
    }
   ],
   "source": [
    "similarities_with_anchor = []\n",
    "for emb in sentence_embeddings:\n",
    "    cos_sim = util.cos_sim(anchor_embedding, emb).item()\n",
    "    similarities_with_anchor.append(cos_sim)\n",
    "\n",
    "print(f\"Similarities with the sentence '{anchor}':\")\n",
    "for i, sentence in enumerate(sentences):\n",
    "    print(f\"{sentence}: {similarities_with_anchor[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likhetssøk i database\n",
    "Vi ser at embeddinger fungerer bra for å sammenlikne konteksten mellom to setninger, uten at ordene som brukes trenger å være helt like. Av denne grunn har det dukket opp flere tjenester som tilbyr å lagre embeddinger og utføre kjappe likhetssøk mellom dokumenter, der eksempler er [Redis Vector Database](https://redis.io/docs/get-started/vector-database/) og [Pinecone](https://www.pinecone.io/).\n",
    "\n",
    "For å utforske hvordan vektordatabaser fungerer i praksis, lager vi en enkel implementasjon selv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorDatabase:\n",
    "    def __init__(self, model: SentenceTransformer):\n",
    "        self.documents = [] # list of strings\n",
    "        self.embeddings = [] # list of torch.Tensors\n",
    "        self.model = model # The SentenceTransformer model to use\n",
    "\n",
    "    def add_document(self, document: str) -> None:\n",
    "        \"\"\"\n",
    "        Add a document to the database. The document will be embedded using the model.\n",
    "\n",
    "        Args:\n",
    "            document (str): The document to add\n",
    "        \"\"\"\n",
    "        self.documents.append(document)\n",
    "        emb = self.model.encode(document, convert_to_tensor=True)\n",
    "        self.embeddings.append(emb)\n",
    "\n",
    "    def similarity_search(self, anchor_document: str, top_k: int = 3):\n",
    "        \"\"\"\n",
    "        Search for the most similar documents to the anchor document.\n",
    "\n",
    "        Args:\n",
    "            anchor_document (str): The document to search for\n",
    "            top_k (int, optional): The number of documents to return. Defaults to 3.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of tuples containing the document and the similarity score\n",
    "        \"\"\"\n",
    "        anchor_emb = self.model.encode(anchor_document, convert_to_tensor=True) # Embed the anchor document\n",
    "        similarities = []\n",
    "        for emb in self.embeddings: # Iterate all the document embeddings\n",
    "            cos_sim = util.cos_sim(anchor_emb, emb).item()\n",
    "            similarities.append(cos_sim)\n",
    "        top_k_similar_indices = torch.topk(torch.tensor(similarities), k=top_k).indices.tolist() # Get the indices of the top k most similar documents\n",
    "        res = [(self.documents[i], similarities[i]) for i in top_k_similar_indices] # Get the documents and their similarity scores\n",
    "        return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [ \n",
    "    \"På norske sykehus brukes det elektroniske pasientjournaler\", \n",
    "    \"Bier er viktige for pollinering av mange av våre matvekster.\",  \n",
    "    \"Mange nordmenn elsker å gå på ski om vinteren.\",  \n",
    "    \"Astronomi er studiet av universet og dets himmellegemer.\",\n",
    "    \"Ute i verdensrommet finnes det mange planeter og stjerner.\",\n",
    "    \"Sjokolade er en populær godbit som lages fra kakaobønner.\",  \n",
    "    \"Fotball er en av de mest populære sportene i verden.\",  \n",
    "    \"Paris er kjent for sin arkitektur, mat og mote.\",  \n",
    "    \"Elefanter er det største landdyret på jorden.\",  \n",
    "    \"Bøker er en viktig kilde til kunnskap og underholdning.\",  \n",
    "    \"Musikk er en universell form for kunst som uttrykker følelser og ideer.\",  \n",
    "    \"Klimaendringer er en stor utfordring for verden i dag.\",\n",
    "    \"Taco er vanlig å spise på fredager\"\n",
    "]  \n",
    "\n",
    "vector_db = VectorDatabase(model)\n",
    "for document in corpus:\n",
    "    vector_db.add_document(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Klimaendringer er en stor utfordring for verden i dag.',\n",
       "  0.5642093420028687)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_document = \"Global oppvarming ødelegger jordkloden\"\n",
    "similar_documents = vector_db.similarity_search(anchor_document, top_k=1)\n",
    "similar_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Astronomi er studiet av universet og dets himmellegemer.',\n",
       "  0.4471147060394287),\n",
       " ('Ute i verdensrommet finnes det mange planeter og stjerner.',\n",
       "  0.43058377504348755),\n",
       " ('Musikk er en universell form for kunst som uttrykker følelser og ideer.',\n",
       "  0.1297227144241333)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_sentence = \"Når det er mørkt og skyfritt kan man se stjerner\"\n",
    "similar_sentences = vector_db.similarity_search(anchor_sentence, top_k=3)\n",
    "similar_sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

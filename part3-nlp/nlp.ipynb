{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    import torch\n",
    "    from IPython.core.display import HTML\n",
    "    from IPython.display import display \n",
    "    import os\n",
    "    print(\"Running in Google Colab\")\n",
    "    if not torch.cuda.is_available():\n",
    "        display(HTML(\"\"\"<div style=\"background-color: red; font-weight: bold; color: white;\">You have not activated a GPU in Google Colab. Follow the instructions in the <code style=\"color: white;\">README</code></div>\"\"\"))\n",
    "    print(\"Installing requirements\")\n",
    "    requirements_url = \"https://raw.githubusercontent.com/willdalh/ml-course/main/requirements.txt\"\n",
    "    if not os.path.exists('requirements.txt'):\n",
    "        !wget {requirements_url}\n",
    "    %pip install --user -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing (NLP)\n",
    "Spr친kteknologi (NLP p친 engelsk) fikk en boost etter at [Transformer-arkitekturen](https://arxiv.org/abs/1706.03762) ble introdusert i 2017. Denne arkitekturen danner grunnlaget for de aller fleste tjenestene som kombinerer AI og spr친k idag, der ChatGPT er et godt eksempel. \n",
    "\n",
    "Siden da har [Hugging Face](huggingface.co) dukket opp som plattform som fors칮ker 친 tilgjengeliggj칮re datasett, implementasjoner og erfaringer innen NLP. Av den grunn vil denne notebooken ta i bruk bibliotekene som tilbys fra dem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fyll inn det manglende ordet\n",
    "Modellen som f칮rst demonstrerte styrken til Transformere, er BERT, som st친r for _Bidirectional Encoder Representations from Transformers_. Den lager alts친 vektorrepresentasjoner av ord ved 친 se p친 b친de ordene som kom f칮r, samt de etterf칮lgende ordene i en setning. Nasjonalbiblioteket har trent en norsk versjon av denne, som vi finner p친 Hugging Face. \n",
    "\n",
    "Vi setter opp en unmasker som tar i bruk en BERT-modell i bunnen for 친 beregne hvilket ord som mangler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4670f32f5545b2880c04ccf0e5eab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599d8908e06f4d4ab0908619c8e55f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 游녤v4.50游녣 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e745a4e9fd654408a20bb08395b08ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed53c502663144159d6d1809e62d50dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c660b1f617b4c2493671a0ee8ef4e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='NbAiLab/nb-bert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'journal'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = unmasker(\"I Norge brukes elektronisk [MASK] p친 sykehusene\")\n",
    "res[0]['token_str']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sammenlikne setninger\n",
    "BERT lager bare embeddinger av enkeltord, men i noen tilfeller 칮nsker vi 친 ha embeddinger for hele setninger, slik at vi kan sammenlikne dem. Til dette bruker vi en Sentence Transformer, og igjen har Nasjonalbiblioteket trent en som vi finner p친 Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a31de92c65469da5ff27ee34015bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08162a8d47644f51982972e64de10502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225efbe408c946888eb874c4d71cc1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/9.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02cd8e2f325c49ce839d43f864b8bae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89764925fb2442fafa953d2be789f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/853 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc99b04fa9944f49956c7f9b9aa788a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/711M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7732716767474c72b0d78be6aa5e64aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/377 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8d522ce3e343188fa31ad271e7e583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7118d38c0c1c47d88cb4d1155497a7cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.92M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a889de7ee429454f802289735ff91545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30fa619596d343cf91ef249a5978a0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('NbAiLab/nb-sbert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "anchor = \"Jeg liker 친 spise iskrem\"\n",
    "anchor_embedding = model.encode(anchor, convert_to_tensor=True)\n",
    "print(anchor_embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi ser at setningen er er blitt gjort om til en vektor med 768 tall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 768])\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"Is er veldig godt\", \"Norske sykehus bruker elektronisk pasientjournal\"]\n",
    "sentence_embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "print(sentence_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi skal n친 sammenlikne embeddingene av de to setningene med anker-setningen. Embeddingene er vektorer/punkter, og det er flere m친ter 친 gj칮re dette p친. Vi bruker cosinus-likhet, som er cosinus av vinkelen som spennes mellom to vektorer. Men man kunne ogs친 brukt Euklidsk avstand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities with the sentence 'Jeg liker 친 spise iskrem':\n",
      "Is er veldig godt: 0.669\n",
      "Norske sykehus bruker elektronisk pasientjournal: 0.069\n"
     ]
    }
   ],
   "source": [
    "similarities_with_anchor = []\n",
    "for emb in sentence_embeddings:\n",
    "    cos_sim = util.cos_sim(anchor_embedding, emb).item()\n",
    "    similarities_with_anchor.append(cos_sim)\n",
    "\n",
    "print(f\"Similarities with the sentence '{anchor}':\")\n",
    "for i, sentence in enumerate(sentences):\n",
    "    print(f\"{sentence}: {similarities_with_anchor[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likhetss칮k i database\n",
    "Vi ser at embeddinger fungerer bra for 친 sammenlikne konteksten mellom to setninger, uten at ordene som brukes trenger 친 v칝re helt like. Av denne grunn har det dukket opp flere tjenester som tilbyr 친 lagre embeddinger og utf칮re kjappe likhetss칮k mellom dokumenter, der eksempler er [Redis Vector Database](https://redis.io/docs/get-started/vector-database/) og [Pinecone](https://www.pinecone.io/).\n",
    "\n",
    "For 친 utforske hvordan vektordatabaser fungerer i praksis, lager vi en enkel implementasjon selv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorDatabase:\n",
    "    def __init__(self, model: SentenceTransformer):\n",
    "        self.documents = [] # list of strings\n",
    "        self.embeddings = [] # list of torch.Tensors\n",
    "        self.model = model # The SentenceTransformer model to use\n",
    "\n",
    "    def add_document(self, document: str) -> None:\n",
    "        \"\"\"\n",
    "        Add a document to the database. The document will be embedded using the model.\n",
    "\n",
    "        Args:\n",
    "            document (str): The document to add\n",
    "        \"\"\"\n",
    "        self.documents.append(document)\n",
    "        emb = self.model.encode(document, convert_to_tensor=True)\n",
    "        self.embeddings.append(emb)\n",
    "\n",
    "    def similarity_search(self, anchor_document: str, top_k: int = 3):\n",
    "        \"\"\"\n",
    "        Search for the most similar documents to the anchor document.\n",
    "\n",
    "        Args:\n",
    "            anchor_document (str): The document to search for\n",
    "            top_k (int, optional): The number of documents to return. Defaults to 3.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of tuples containing the document and the similarity score\n",
    "        \"\"\"\n",
    "        anchor_emb = self.model.encode(anchor_document, convert_to_tensor=True) # Embed the anchor document\n",
    "        similarities = []\n",
    "        for emb in self.embeddings: # Iterate all the document embeddings\n",
    "            cos_sim = util.cos_sim(anchor_emb, emb).item()\n",
    "            similarities.append(cos_sim)\n",
    "        top_k_similar_indices = torch.topk(torch.tensor(similarities), k=top_k).indices.tolist() # Get the indices of the top k most similar documents\n",
    "        res = [(self.documents[i], similarities[i]) for i in top_k_similar_indices] # Get the documents and their similarity scores\n",
    "        return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [ \n",
    "    \"P친 norske sykehus brukes det elektroniske pasientjournaler\", \n",
    "    \"Bier er viktige for pollinering av mange av v친re matvekster.\",  \n",
    "    \"Mange nordmenn elsker 친 g친 p친 ski om vinteren.\",  \n",
    "    \"Astronomi er studiet av universet og dets himmellegemer.\",\n",
    "    \"Ute i verdensrommet finnes det mange planeter og stjerner.\",\n",
    "    \"Sjokolade er en popul칝r godbit som lages fra kakaob칮nner.\",  \n",
    "    \"Fotball er en av de mest popul칝re sportene i verden.\",  \n",
    "    \"Paris er kjent for sin arkitektur, mat og mote.\",  \n",
    "    \"Elefanter er det st칮rste landdyret p친 jorden.\",  \n",
    "    \"B칮ker er en viktig kilde til kunnskap og underholdning.\",  \n",
    "    \"Musikk er en universell form for kunst som uttrykker f칮lelser og ideer.\",  \n",
    "    \"Klimaendringer er en stor utfordring for verden i dag.\",\n",
    "    \"Taco er vanlig 친 spise p친 fredager\"\n",
    "]  \n",
    "\n",
    "vector_db = VectorDatabase(model)\n",
    "for document in corpus:\n",
    "    vector_db.add_document(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Klimaendringer er en stor utfordring for verden i dag.',\n",
       "  0.5642092227935791)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_document = \"Global oppvarming 칮delegger jordkloden\"\n",
    "similar_documents = vector_db.similarity_search(anchor_document, top_k=1)\n",
    "similar_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Astronomi er studiet av universet og dets himmellegemer.',\n",
       "  0.4471149444580078),\n",
       " ('Ute i verdensrommet finnes det mange planeter og stjerner.',\n",
       "  0.4305839240550995),\n",
       " ('Musikk er en universell form for kunst som uttrykker f칮lelser og ideer.',\n",
       "  0.12972286343574524)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_sentence = \"N친r det er m칮rkt og skyfritt kan man se stjerner\"\n",
    "similar_sentences = vector_db.similarity_search(anchor_sentence, top_k=3)\n",
    "similar_sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

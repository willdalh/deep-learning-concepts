{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN model trained to predict the next word in a sentence\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, target_sentences):\n",
    "        super().__init__()\n",
    "        self.target_sentences = [f\"<START> {sentence.strip().lower()} <END>\" for sentence in target_sentences]\n",
    "        self.vocab = list(set(\" \".join(self.target_sentences).split(\" \")))\n",
    "\n",
    "        self.hidden_size = 128\n",
    "        self.embedding_size = 64\n",
    "\n",
    "        self.last_layer = nn.Linear(self.hidden_size, len(self.vocab))\n",
    "        self.embedding = nn.Embedding(len(self.vocab), self.embedding_size)\n",
    "        self.internal_layer = nn.Linear(self.embedding_size + self.hidden_size, self.hidden_size)\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "    \n",
    "    def tokenize(self, word):\n",
    "        return torch.LongTensor([self.vocab.index(word)])\n",
    "\n",
    "    def logits(self, sentence):\n",
    "\n",
    "        # Initialize hidden state for sequence\n",
    "        hidden = torch.zeros(1, self.hidden_size)\n",
    "\n",
    "        # Process each token in the sequence\n",
    "        split = sentence.split(\" \")\n",
    "        # Check if the word is in the vocab\n",
    "        if not all([word in self.vocab for word in split]):\n",
    "            raise ValueError(\"Word not in vocab\")\n",
    "        \n",
    "        # Iterate through each word in the sequence\n",
    "        for elem in split:\n",
    "            token = self.tokenize(elem)\n",
    "            embedding = self.embedding(token)\n",
    "            input_data = torch.cat((embedding, hidden), dim=1)\n",
    "            hidden = self.internal_layer(input_data)\n",
    "            hidden = F.tanh(hidden)\n",
    "            \n",
    "        # The last hidden state should go through the last layer\n",
    "        output = self.last_layer(hidden)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def get_prob_dist_over_next_word(self, sentence: str):\n",
    "        dist = self.forward(sentence)[0]\n",
    "        return {self.vocab[i]: f\"{dist[i].item():.2f}\" for i in range(len(dist))}\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        return F.softmax(self.logits(sentence), dim=1)\n",
    "    \n",
    "    def predict(self, sentence):\n",
    "        result = self.vocab[torch.argmax(self.forward(sentence.strip()))]\n",
    "        return result\n",
    "    \n",
    "    def complete_sentence(self, sentence, max_len=100):\n",
    "        result = sentence.strip()\n",
    "        new_token = \"\"\n",
    "        while not new_token == \"<END>\":\n",
    "            new_token = self.predict(result)\n",
    "            if len(result.split(\" \")) >= max_len:\n",
    "                break\n",
    "            result += \" \" + new_token\n",
    "        return result\n",
    "\n",
    "    def train(self, num_epochs=10):\n",
    "        for epoch in tqdm(range(num_epochs), unit=\"epoch\"):\n",
    "            for sentence in self.target_sentences:\n",
    "                split_sentence = sentence.split(\" \")\n",
    "                for i in range(len(split_sentence) - 1):\n",
    "                    self.optimizer.zero_grad()\n",
    "                    input_data = split_sentence[:i+1]\n",
    "                    target = split_sentence[i+1]\n",
    "                    output = self.forward(\" \".join(input_data))\n",
    "                    loss = self.loss_fn(output, self.tokenize(target))\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "        \n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Før vi trener modellen sjekker vi at den **ikke** klarer å skrive setninger som gir mening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START> dette lærer kodekurset <START> er <START> er lærer er kodekurset <START> dette lærer er lærer er kodekurset <START> dette lærer er lærer er kodekurset <START> dette lærer er lærer er kodekurset <START> dette lærer er lærer er kodekurset <START> dette lærer er lærer er kodekurset <START> dette lærer er lærer er kodekurset <START> dette lærer er lærer er kodekurset <START> dette lærer er lærer er kodekurset <START> dette lærer er lærer er kodekurset <START> dette lærer er lærer er kodekurset <START> dette lærer er lærer er kodekurset <START> dette lærer er lærer er kodekurset <START> dette lærer er lærer'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_sentences = [\"dette er et kodekurs i maskinlæring\", \"kodekurset er gøy fordi man lærer mye\"]\n",
    "rnn = RNNModel(target_sentences)\n",
    "rnn.complete_sentence(\"<START> \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 32.19epoch/s]\n"
     ]
    }
   ],
   "source": [
    "rnn.train(num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START> dette er et kodekurs i maskinlæring <END>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.complete_sentence(\"<START> dette\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'er': '0.00',\n",
       " 'kodekurs': '0.97',\n",
       " 'i': '0.00',\n",
       " 'et': '0.00',\n",
       " 'kodekurset': '0.00',\n",
       " 'maskinlæring': '0.00',\n",
       " 'lærer': '0.00',\n",
       " 'gøy': '0.00',\n",
       " '<START>': '0.00',\n",
       " '<END>': '0.00',\n",
       " 'dette': '0.00',\n",
       " 'mye': '0.00',\n",
       " 'man': '0.00',\n",
       " 'fordi': '0.01'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.get_prob_dist_over_next_word(\"<START> dette er et\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START> innsjøen sov morsom rolig morgen kan bok rask bordet stjernene tre. gir gjør under tre. gir et mat rolig bilde full katten gå et morsom bygger sunn aktiv opplevelse. sjøen mat morsom rolig morgen kan bok rask bordet stjernene tre. gir gjør under tre. gir et mat rolig bilde full katten gå et morsom bygger sunn aktiv opplevelse. sjøen mat morsom rolig morgen kan bok rask bordet stjernene tre. gir gjør under tre. gir et mat rolig bilde full katten gå et morsom bygger sunn aktiv opplevelse. sjøen mat morsom rolig morgen kan bok rask bordet stjernene tre. gir'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences  = [\n",
    "    \"Katten sov rolig under det store treet.\",\n",
    "    \"En rolig dag ved sjøen kan være veldig avslappende.\",\n",
    "    \"Han leste en bok under et skyggefullt tre.\",\n",
    "    \"Solen skinte sterkt, og fuglene sang vakkert.\",\n",
    "    \"En rask løpetur om morgenen gjør meg energisk for dagen.\",\n",
    "    \"Hun malte et bilde av et fargerikt tre.\",\n",
    "    \"Å lage mat sammen kan være en morsom aktivitet.\",\n",
    "    \"Vannet i innsjøen var krystallklart og rolig.\",\n",
    "    \"En bok om eventyr kan være veldig spennende.\",\n",
    "    \"Morgensolen varmer og gir energi til en ny dag.\",\n",
    "    \"Han spilte gitar under stjernene og sang rolig.\",\n",
    "    \"Å gå på tur i skogen kan være både fredelig og energigivende.\",\n",
    "    \"Boken på bordet er full av interessante historier.\",\n",
    "    \"Fuglene bygger reir i det høye treet.\",\n",
    "    \"Å se på stjernene om natten er en fredelig opplevelse.\",\n",
    "    \"Å spise sunn mat gir god energi for kroppen.\",\n",
    "    \"En rolig spasertur i parken kan være veldig hyggelig.\",\n",
    "    \"Å lese bøker under et tre er en av mine favorittaktiviteter.\",\n",
    "    \"Morgendugg på bladene skinte som små diamanter.\",\n",
    "    \"Trening hver morgen holder meg aktiv og energisk.\"\n",
    "]\n",
    "rnn = RNNModel(sentences)\n",
    "rnn.complete_sentence(\"<START>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:25<00:00,  1.99epoch/s]\n"
     ]
    }
   ],
   "source": [
    "rnn.train(num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START> å se på stjernene om natten er en fredelig opplevelse. <END>'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.complete_sentence(\"<START> \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, target_sentences):\n",
    "        super().__init__()\n",
    "        self.target_sentences = [f\"<START> {sentence.strip().lower()} <END>\" for sentence in target_sentences]\n",
    "        self.vocab = list(set(\" \".join(self.target_sentences).split(\" \")))\n",
    "\n",
    "        self.hidden_size = 128\n",
    "        self.embedding_size = 64\n",
    "\n",
    "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, batch_first=True, bidirectional=False)\n",
    "        self.last_layer = nn.Linear(self.hidden_size, len(self.vocab))\n",
    "        self.embedding = nn.Embedding(len(self.vocab), self.embedding_size)\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "    \n",
    "    def tokenize(self, word):\n",
    "        return torch.LongTensor([self.vocab.index(word)])\n",
    "\n",
    "    def logits(self, sentence):\n",
    "        # Initialize hidden and cell state for sequence\n",
    "        hidden = torch.zeros(1, 1, self.hidden_size)\n",
    "        cell = torch.zeros(1, 1, self.hidden_size)\n",
    "\n",
    "        # Process each token in the sequence\n",
    "        split = sentence.split(\" \")\n",
    "        if not all([word in self.vocab for word in split]):\n",
    "            raise ValueError(\"Word not in vocab\")\n",
    "        \n",
    "        # Embedding layer\n",
    "        tokenized = [self.tokenize(word) for word in split]\n",
    "        embedded = self.embedding(torch.stack(tokenized).squeeze(1))    \n",
    "        embedded = embedded.view(1, len(embedded), -1)\n",
    "\n",
    "        # LSTM layer\n",
    "        lstm_out, _ = self.lstm(embedded, (hidden, cell))\n",
    "        output = self.last_layer(lstm_out[:, -1])\n",
    "        return output\n",
    "\n",
    "    def get_prob_dist_over_next_word(self, sentence: str):\n",
    "        dist = self.forward(sentence)[0]\n",
    "        return {self.vocab[i]: f\"{dist[i].item():.2f}\" for i in range(len(dist))}\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        return F.softmax(self.logits(sentence), dim=1)\n",
    "    \n",
    "    def predict(self, sentence):\n",
    "        result = self.vocab[torch.argmax(self.forward(sentence))]\n",
    "        return result\n",
    "    \n",
    "    def complete_sentence(self, sentence, max_len=100):\n",
    "        result = sentence.strip()\n",
    "        new_token = \"\"\n",
    "        while not new_token == \"<END>\":\n",
    "            new_token = self.predict(result)\n",
    "            if len(result.split(\" \")) >= max_len:\n",
    "                break\n",
    "            result += \" \" + new_token\n",
    "        return result\n",
    "\n",
    "    def train(self, num_epochs=10):\n",
    "        for epoch in tqdm(range(num_epochs), unit=\"epoch\"):\n",
    "            for sentence in self.target_sentences:\n",
    "                split_sentence = sentence.split(\" \")\n",
    "                for i in range(len(split_sentence) - 1):\n",
    "                    self.optimizer.zero_grad()\n",
    "                    input_data = split_sentence[:i+1]\n",
    "                    target = split_sentence[i+1]\n",
    "                    output = self.forward(\" \".join(input_data))\n",
    "                    loss = self.loss_fn(output, self.tokenize(target))\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START> mens fylte blomstret blomstret blomstret skyggefulle mens fylte blomstret blomstret skyggefulle mens fylte blomstret blomstret skyggefulle mens fylte blomstret blomstret skyggefulle mens fylte blomstret blomstret skyggefulle mens fylte blomstret blomstret skyggefulle mens fylte blomstret blomstret skyggefulle mens fylte blomstret blomstret skyggefulle mens fylte blomstret blomstret skyggefulle mens fylte blomstret blomstret skyggefulle mens fylte blomstret blomstret skyggefulle mens fylte blomstret blomstret skyggefulle mens fylte blomstret blomstret skyggefulle mens fylte blomstret blomstret skyggefulle mens fylte blomstret blomstret skyggefulle mens fylte blomstret blomstret skyggefulle mens fylte blomstret blomstret skyggefulle mens fylte blomstret blomstret skyggefulle mens fylte blomstret blomstret skyggefulle mens fylte blomstret'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = LSTMModel(sentences)\n",
    "lstm.complete_sentence(\"<START> \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:15<00:00,  6.36epoch/s]\n"
     ]
    }
   ],
   "source": [
    "lstm.train(num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START> parken i parken sang fuglene mens folk gikk på stier. <END>'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.complete_sentence(\"<START> parken\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

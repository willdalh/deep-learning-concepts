{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN model trained to predict the next word in a sentence\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, target_sentences):\n",
    "        super().__init__()\n",
    "        self.target_sentences = [f\"<START> {sentence} <END>\" for sentence in target_sentences]\n",
    "        self.vocab = list(set(\" \".join(self.target_sentences).split(\" \")))\n",
    "\n",
    "        self.hidden_size = 128\n",
    "        self.embedding_size = 64\n",
    "\n",
    "        self.last_layer = nn.Linear(self.hidden_size, len(self.vocab))\n",
    "        self.embedding = nn.Embedding(len(self.vocab), self.embedding_size)\n",
    "        self.internal_layer = nn.Linear(self.embedding_size + self.hidden_size, self.hidden_size)\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "    \n",
    "    def tokenize(self, word):\n",
    "        return torch.LongTensor([self.vocab.index(word)])\n",
    "\n",
    "    def logits(self, sentence):\n",
    "\n",
    "        # Initialize hidden state for sequence\n",
    "        hidden = torch.zeros(1, self.hidden_size)\n",
    "\n",
    "        # Process each token in the sequence\n",
    "        split = sentence.split(\" \")\n",
    "        # Check if the word is in the vocab\n",
    "        if not all([word in self.vocab for word in split]):\n",
    "            raise ValueError(\"Word not in vocab\")\n",
    "        \n",
    "        # Iterate through each word in the sequence\n",
    "        for elem in split:\n",
    "            token = self.tokenize(elem)\n",
    "            embedding = self.embedding(token)\n",
    "            input_data = torch.cat((embedding, hidden), dim=1)\n",
    "            hidden = self.internal_layer(input_data)\n",
    "            \n",
    "        # The last hidden state should go through the last layer\n",
    "        output = self.last_layer(hidden)\n",
    "\n",
    "        return output\n",
    "    \n",
    "\n",
    "    def forward(self, sentence):\n",
    "        return F.softmax(self.logits(sentence), dim=1)\n",
    "    \n",
    "    def predict(self, sentence):\n",
    "        # sentence = f\"<START> {sentence}\"\n",
    "        result = self.vocab[torch.argmax(self.forward(sentence))]\n",
    "        # if result == \"<END>\":\n",
    "        #     return \"\"\n",
    "        return result\n",
    "    \n",
    "    def complete_sentence(self, sentence):\n",
    "        sentence = f\"<START> {sentence}\"\n",
    "        new_token = self.predict(sentence)\n",
    "        while new_token != \"<END>\":\n",
    "            sentence += \" \" + new_token\n",
    "            new_token = self.predict(sentence)\n",
    "        return sentence\n",
    "\n",
    "    def run_epoch(self, do_test=False):\n",
    "        for sentence in self.target_sentences:\n",
    "            split_sentence = sentence.split(\" \")\n",
    "        \n",
    "            for i in range(len(split_sentence) - 1):\n",
    "                self.optimizer.zero_grad()\n",
    "                input_data = split_sentence[:i+1]\n",
    "                target = split_sentence[i+1]\n",
    "                output = self.forward(\" \".join(input_data))\n",
    "                loss = self.loss_fn(output, self.tokenize(target))\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        # if do_test:\n",
    "        #     curr_token = \"<START>\"\n",
    "        #     for i in range(100):\n",
    "        #         curr_token = self.predict(curr_token)\n",
    "        #         print(curr_token, end=\" \")\n",
    "        #         if curr_token == \"<END>\":\n",
    "        #             break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sentences = [\"dette er et kodekurs i maskinlæring\", \"kodekurset er gøy\"]\n",
    "rnn = RNNModel(target_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Før vi trener modellen sjekker vi at den ikke klarer å skrive setninger som gir mening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kodekurset'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.predict(\"dette er et kodekurs i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 24.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    rnn.run_epoch(do_test=epoch % 10 == 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START> dette er et kodekurs i maskinlæring'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.complete_sentence(\"dette\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

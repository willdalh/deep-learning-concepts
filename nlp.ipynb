{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing (NLP)\n",
    "Språkteknologi (NLP på engelsk) fikk en boost etter at [Transformer-arkitekturen](https://arxiv.org/abs/1706.03762) ble introdusert i 2017. Denne arkitekturen danner grunnlaget for de aller fleste tjenestene som kombinerer AI og språk idag, der ChatGPT er et godt eksempel. \n",
    "\n",
    "Siden da har [Hugging Face](huggingface.co) dukket opp som plattform som forsøker å tilgjengeliggjøre datasett, implementasjoner og erfaringer innen NLP. Av den grunn vil denne notebooken ta i bruk bibliotekene som tilbys fra dem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fyll inn det manglende ordet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='NbAiLab/nb-bert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'journal'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = unmasker(\"Sykehusene bruker elektronisk [MASK].\")\n",
    "res[0]['token_str']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sammenlikne setninger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('NbAiLab/nb-sbert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "anchor = \"Jeg liker å spise iskrem\"\n",
    "anchor_embedding = model.encode(anchor, convert_to_tensor=True)\n",
    "print(anchor_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 768])\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"Is er veldig godt\", \"Norske sykehus bruker elektronisk pasientjournal.\"]\n",
    "sentence_embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "print(sentence_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi skal nå sammenlikne embeddingene av de to setningene med anker-setningen. Embeddingene er vektorer/punkter, og det er flere måter å gjøre dette på. Vi bruker cosinus-likhet, som er cosinus av vinkelen som spennes mellom to vektorer. Men man kunne også brukt Euklidsk avstand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities with the sentence 'Jeg liker å spise iskrem':\n",
      "Is er veldig godt: 0.669\n",
      "Norske sykehus bruker elektronisk pasientjournal.: 0.078\n"
     ]
    }
   ],
   "source": [
    "similarities_with_anchor = []\n",
    "for emb in sentence_embeddings:\n",
    "    cos_sim = util.cos_sim(anchor_embedding, emb).item()\n",
    "    similarities_with_anchor.append(cos_sim)\n",
    "\n",
    "print(f\"Similarities with the sentence '{anchor}':\")\n",
    "for i, sentence in enumerate(sentences):\n",
    "    print(f\"{sentence}: {similarities_with_anchor[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likhetssøk i database\n",
    "Vi ser at embeddinger fungerer bra for å sammenlikne konteksten mellom to setninger, uten at ordene som brukes trenger å være helt like. Av denne grunn har det dukket opp flere tjenester som tilbyr å lagre embeddinger og utføre kjappe likhetssøk mellom dokumenter, der eksempler er [Redis Vector Database](https://redis.io/docs/get-started/vector-database/) og [Pinecone](https://www.pinecone.io/).\n",
    "\n",
    "For å utforske hvordan vektordatabaser fungerer i praksis, lager vi en enkel implementasjon selv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorDatabase:\n",
    "    def __init__(self, model: SentenceTransformer):\n",
    "        self.documents = [] # list of strings\n",
    "        self.embeddings = [] # list of torch.Tensors\n",
    "        self.model = model # The SentenceTransformer model to use\n",
    "\n",
    "    def add_document(self, document: str) -> None:\n",
    "        \"\"\"\n",
    "        Add a document to the database. The document will be embedded using the model.\n",
    "\n",
    "        Args:\n",
    "            document (str): The document to add\n",
    "        \"\"\"\n",
    "        self.documents.append(document)\n",
    "        emb = self.model.encode(document, convert_to_tensor=True)\n",
    "        self.embeddings.append(emb)\n",
    "\n",
    "    def similarity_search(self, anchor_document: str, top_k: int = 5):\n",
    "        \"\"\"\n",
    "        Search for the most similar documents to the anchor document.\n",
    "\n",
    "        Args:\n",
    "            anchor_document (str): The document to search for\n",
    "            top_k (int, optional): The number of documents to return. Defaults to 5.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of tuples containing the document and the similarity score\n",
    "        \"\"\"\n",
    "        anchor_emb = self.model.encode(anchor_document, convert_to_tensor=True)\n",
    "        similarities = []\n",
    "        for emb in self.embeddings:\n",
    "            cos_sim = util.cos_sim(anchor_emb, emb).item()\n",
    "            similarities.append(cos_sim)\n",
    "        top_k_similar_indices = torch.topk(torch.tensor(similarities), k=top_k).indices.tolist()\n",
    "        res = [(self.documents[i], similarities[i]) for i in top_k_similar_indices]\n",
    "        return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [ \n",
    "    \"På norske sykehus brukes det elektroniske pasientjournaler\", \n",
    "    \"Bier er viktige for pollinering av mange av våre matvekster.\",  \n",
    "    \"Mange nordmenn elsker å gå på ski om vinteren.\",  \n",
    "    \"Astronomi er studiet av universet og dets himmellegemer.\",\n",
    "    \"Ute i verdensrommet finnes det mange planeter og stjerner.\",\n",
    "    \"Sjokolade er en populær godbit som lages fra kakaobønner.\",  \n",
    "    \"Fotball er en av de mest populære sportene i verden.\",  \n",
    "    \"Paris er kjent for sin arkitektur, mat og mote.\",  \n",
    "    \"Elefanter er det største landdyret på jorden.\",  \n",
    "    \"Bøker er en viktig kilde til kunnskap og underholdning.\",  \n",
    "    \"Musikk er en universell form for kunst som uttrykker følelser og ideer.\",  \n",
    "    \"Klimaendringer er en stor utfordring for verden i dag.\",\n",
    "    \"Taco er vanlig å spise på fredager\"\n",
    "]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = VectorDatabase(model)\n",
    "for document in documents:\n",
    "    vector_db.add_document(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Klimaendringer er en stor utfordring for verden i dag.',\n",
       "  0.5642093420028687)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_document = \"Global oppvarming ødelegger jordkloden\"\n",
    "similar_documents = vector_db.get_most_similar(anchor_document, top_k=1)\n",
    "similar_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Astronomi er studiet av universet og dets himmellegemer.',\n",
       "  0.4471147060394287),\n",
       " ('Ute i verdensrommet finnes det mange planeter og stjerner.',\n",
       "  0.43058377504348755),\n",
       " ('Musikk er en universell form for kunst som uttrykker følelser og ideer.',\n",
       "  0.1297227144241333)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_sentence = \"Når det er mørkt og skyfritt kan man se stjerner\"\n",
    "similar_sentences = vector_db.get_most_similar(anchor_sentence, top_k=3)\n",
    "similar_sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

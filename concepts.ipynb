{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kræsjkurs i AI - Grunnleggende prinsipper\n",
    "\n",
    "<img src=\"https://media.licdn.com/dms/image/D5612AQE4PAb7ReqhRg/article-cover_image-shrink_600_2000/0/1679715986172?e=2147483647&v=beta&t=LlQEO0Tf583irseJlj3G3BI2pvpJaLyGM_gxALuwB0E\">\n",
    "\n",
    "\n",
    "- Maskinlæring er så mangt\n",
    "- Vis litt at det ikke bare er nevrale nettverk.\n",
    "- Hva betyr \"dyp\"\n",
    "\n",
    "Hvorfor går kodebiten bare gjennom Dyp læring?\n",
    "- Flesteparten av modellene som imponerer oss idag er dype nevrale nettverk\n",
    "    - ChatGPT\n",
    "    - GPT-4\n",
    "    - Stable Diffusion\n",
    "    - Midjourney\n",
    "    - AlphaZero\n",
    "    - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Den tekniske biten - Hvordan ser det ut å jobbe med nevrale nettverk nå til dags?\n",
    "Denne er ment for å gi et kjapt overblikk av hvordan kode ser ut når man jobber med maskinlæring / dyp læring.\n",
    "\n",
    "## Vektorer\n",
    "I dyp læring er all data i form av vektorer, matriser og tensorer. Min faglige erfaring tilsier at disse begrepene er generelle og beskriver bare en samling verdier. Rent praktisk er det flerdimensjonale lister/arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensjoner og _shapes_\n",
    "Fra matematikken vet vi at en liste med feks. 3 tall definerer en vektor/punkt som lever i et tre-dimensjonalt rom. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rammeverket PyTorch\n",
    "\n",
    "PyTorch er et av flere biblioteker som brukes til trening av dype nevrale nettverk. Det andre kjente alternativet er TensorFlow. Hva man velger avhenger mye av smak, men begge har sine fordeler og ulemper. Jeg liker PyTorch fordi mindre av treningsprosessen blir gjemt og man har mer frihet.\n",
    "PyTorch omfatter mye av den funksjonaliteten man finner i Numpy, men tilbyr metoder for trening og konstruksjon av nevrale nettverk. En `np.ndarray` er ekvivalent med en `torch.Tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8891, -0.7840],\n",
      "        [-0.0148,  0.0198]])\n",
      "Default tensor location: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randn(2, 2)\n",
    "print(tensor)\n",
    "print(f\"Default tensor location: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8891, -0.7840],\n",
       "        [-0.0148,  0.0198]], device='cuda:0')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppsett av nevrale nettverk med PyTorch\n",
    "Et nevralt nettverk har vanligvis en kompleks struktur. Likevel består de av flere isolerte komponenter, og disse finner man i `torch.nn`. \n",
    "\n",
    "De fleste komponentene blir et såkalt _lag_ i nettverket, mens andre komponenter anvendes på eksisterende lag (feks aktiveringsfunksjoner). \n",
    "\n",
    "Den enkleste er `torch.nn.Linear`, og setter opp et lineært lag. Matematisk gjør den en lineær transformasjon fra et vektorrom til et annet. Feks kan den ta inn en vektor med 5 elementer, og outputte en vektor med 3 elementer:\n",
    "\n",
    "<img src=\"nn_5in_3out-cropped.svg\" width=\"500px\" height=\"auto\" alt=\"SVG Image\"  style=\"filter: invert(100%); \"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=5, out_features=3, bias=True)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "layer = nn.Linear(in_features=5, out_features=3) # Construct layer\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vector: tensor([[1., 2., 3., 4., 5.]])\n",
      "Output vector: tensor([[-1.4865,  1.1332,  0.4413]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "data = torch.Tensor([[1, 2, 3, 4, 5]])\n",
    "print(f\"Input vector: {data}\")\n",
    "output = layer(data) # Feed data into layer\n",
    "print(f\"Output vector: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      "tensor([[-0.2804, -0.3011, -0.4440, -0.3323,  0.3439],\n",
      "        [ 0.4349, -0.0922,  0.0253,  0.3383, -0.0868],\n",
      "        [ 0.3337, -0.2095,  0.3113, -0.4153,  0.1802]])\n",
      "Weight shape: torch.Size([3, 5])\n",
      "\n",
      "Bias:\n",
      "tensor([ 0.3375, -0.1122,  0.3529])\n",
      "Bias shape: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Weights:\\n{layer.weight.data}\")\n",
    "print(f\"Weight shape: {layer.weight.shape}\\n\")\n",
    "\n",
    "print(f\"Bias:\\n{layer.bias.data}\")\n",
    "print(f\"Bias shape: {layer.bias.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Når man sender input-vektoren inn skjer følgende operasjon (hvor `@` er matrisemultiplikasjon):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4865,  1.1332,  0.4413]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data @ layer.weight.T + layer.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi ser fra resultatet over at det stemmer .\n",
    "\n",
    "\n",
    "Vektene og biaset utgjør til sammen **parametrene**, og er verdiene som endres under trening. Hvordan disse er strukturert og brukes varierer. Konvolusjonelle lag bruker en \"sliding window\"-mekanisme hvor de samme vektene multipliseres med forskjellige deler av et bilde. Til denne introduksjon holder vi oss derimot til lineære lag. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aktiveringsfunksjoner\n",
    "\n",
    "Det lineære laget utfører en lineær operasjon. Fleksibiliteten av nevrale nettverk kommer derimot av såkalte _aktiveringsfunksjoner_ som utfører ikke-lineære operasjoner på data. Disse inneholder **vanligvis ikke** trenbare parametre. De enkleste opererer på hvert element individuelt, som feks Sigmoid. Vi ser på et en-dimensjonalt-case for å visualisere det enkelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt # Library for visualization\n",
    "sigmoid = nn.Sigmoid()\n",
    "assert not hasattr(sigmoid, \"weight\") # No learnable weights\n",
    "\n",
    "data = torch.linspace(start=-6, end=6, steps=100) # One-dimensional vector with 100 elements \n",
    "output = sigmoid(data)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "\n",
    "ax.plot(data, output)\n",
    "ax.set_xlabel(\"Input data\")\n",
    "ax.set_ylabel(\"Sigmoid Output\")\n",
    "\n",
    "# Add a grid\n",
    "ax.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et viktig poeng er at aktiveringsfunksjoner ikke modifiserer _shapen_ til tensoren. Dette kan demonstreres på en tensor med flere shape-dimensjoner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before activation function: torch.Size([30, 5, 15])\n",
      "shape after activation function: torch.Size([30, 5, 15])\n"
     ]
    }
   ],
   "source": [
    "data = torch.rand(30, 5, 15)\n",
    "print(f\"shape before activation function: {data.shape}\")\n",
    "data = sigmoid(data)\n",
    "shape2 = print(f\"shape after activation function: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En annen viktig er `nn.Softmax`, og brukes til å transformere en vektor til elementer som summeres til 1. \n",
    "\n",
    "Dette gjør den litt annerledes enn Sigmoid, siden vi må spesifisere en av shape-dimensjonene som skal summeres til 1.\n",
    "\n",
    "Passer fint som siste lag i et nettverk man ønsker skal modellere en sannsynlighetsfordeling (Total sannsynlighet av alle utfallene av en stokastisk variabel skal være 1). Derfor er den veldig relevant for NLP, siden de fleste språkmodeller lærer seg en betinget sannsynlighetsfordeling over ord gitt tidligere tekst. \n",
    "\n",
    "For denne anledningen tar vi også i bruk `nn.functional`, som er et delbibliotek som tilbyr mange av komponentene tilstandsfrie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "tensor([[-1.0453,  0.8811,  0.5238],\n",
      "        [-1.1572,  0.9512, -0.2964],\n",
      "        [ 0.7826,  1.0887, -0.0656]])\n",
      "Transformed data:\n",
      "tensor([[0.0789, 0.5419, 0.3791],\n",
      "        [0.0862, 0.7099, 0.2039],\n",
      "        [0.3589, 0.4874, 0.1537]])\n",
      "Summing individual batch elements:\n",
      "tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# data = torch.Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "data = torch.randn(3, 3)\n",
    "print(f\"Original data:\\n{data}\")\n",
    "data = F.softmax(data, dim=1)\n",
    "print(f\"Transformed data:\\n{data}\")\n",
    "print(f\"Summing individual batch elements:\\n{data.sum(dim=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifisering av sifre\n",
    "Vi skal sette opp et nevralt nettverk som er i stand til å klassifisere sifre. Til det trenger vi det lett tilgjengelige MNIST-datasettet. Dette lastes ned gjennom torchvision-biblioteket. Torchvision-biblioteket er et hjelpebibliotek som tilbyr verktøy for Computer Vision-oppgaver. \n",
    "\n",
    "Datasett kommer vanligvis i et rå-format, og må behandles for å tilpasse det oppgaven vi skal gjøre. I dette tilfellet får vi PNG-bilder som må gjøres om til tensorer. Vi normaliserer også bildene for å få [bedre resultater](https://developers.google.com/machine-learning/data-prep/transform/normalization). Behandlingen gjøres med `torchvision.transforms`-biblioteket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Pipeline of processing operations\n",
    "image_processing = transforms.Compose([\n",
    "    transforms.ToTensor(), # Cast into tensor\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Pixel-values will range in [-1, 1]\n",
    "    ])\n",
    "\n",
    "train_dataset = MNIST(root='./data', train=True, transform=image_processing, download=True)\n",
    "test_dataset = MNIST(root='./data', train=False, transform=image_processing, download=True) # Test data for later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I maskinlæring trener man flere epoker (iterasjoner) på samme datasettet. \n",
    "\n",
    "Hver epoke inneholder flere iterasjoner som består av å oppdatere vektene på et lite subset av datasettet. Man kaller dette for en batch. Denne logikken oppnår vi delvis gjennom `torch.utils.data.DataLoader`. Resten kommer når selve treningen skjer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data batch: torch.Size([32, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32) # Iterable that provides 16 data samples each iteration\n",
    "\n",
    "data, labels = next(iter(train_loader)) # Retrieve a batch of data samples and labels for inspection purposes\n",
    "print(f\"Shape of data batch: {data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensoren inneholder 16 eksemplarer, 1 fargekanal (grayscale), 28 piksler i høyden, og 28 piksler i bredden.\n",
    "Vi kan visualisere et tilfeldig eksemplar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shown below is the digit 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAACcklEQVR4nO3dP46NURzH4etPbIUomZKNSFQ6K7ACa2ADaqsQiWYahdICLMHQOO9ILjrnEb/PU53ckdxvPk7xxlwzp1OSJEmSJEmSJEmSJEmSJEmS5P9zY+/bfViHh+vw6vja871TfrhJ3vUfUgA9QCuAHqAVQA/Qxge4vfftvq3D1dkryPgbUAA9QCuAHqAVQA/QCqAHaAXQA7QC6AFaAfQArQB6gFYAPUArgB6gFUAP0AqgB2gF0AO0zd8bPHrfWofNn9I6M/4GFEAP0AqgB2gF0AO08QE2Pwgdn436ug73jq/dXYdP2+acugEFKIAeoBVAD9AKoAdomx+Ezj06To/XoQehnQqgB2gF0AO0AugB2vgAmx+Enq7Dx73v+3vjb0AB9ACtAHqAVgA9QBsfQH1E5+rscO1iHS43DBl/AwqgB2gF0AO0AugB2vgA6ltjf3oQ2mr8DSiAHqAVQA/QCqAHaAXQAzT1JPhyHV6gAcv4G1AAPUArgB6gFUAP0MYHUA9Cb9ehByGsAHqAVgA9QCuAHqCND8D/29wv/gbur8Olef9ZCqAHaAXQA7QC6AHa+ADq0+IP1uH9H/7QnQ1Dxt+AAugBWgH0AK0AeoA2PoD6F6HP6/DmeOkJGTL+BhRAD9AKoAdoBdADtPEB1IPQl3V4d7zUgxBRAD1AK4AeoBVAD9DGB9C/6+wnr9fh2TpcrsPF6a8ZfwMKoAdoBdADtALoAVoB9ACNf1r82vkPl9rxU6bG34AC6AFaAfQArQB6gFYAPUArgB6gFUAP0AqgB2gF0AO0AugBWgH0AK0AeoBWAD1AGx8gSZIkSZIkSZIkGeI7aXIeMlNwrG0AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def visualize(tensor):\n",
    "    image = transforms.functional.resize((tensor+1)/2, (256, 256), interpolation=transforms.InterpolationMode.NEAREST) # Upscaling for visual purposes\n",
    "    image = transforms.functional.to_pil_image(image)\n",
    "    return image\n",
    "\n",
    "import random\n",
    "rand_index = random.randint(0, len(data)-1)\n",
    "data_sample = data[rand_index]\n",
    "label_sample = labels[rand_index]\n",
    "\n",
    "print(f\"Shown below is the digit {label_sample}\")\n",
    "visualize(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Og tensoren i seg selv ser slik ut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.5922,  0.9922,\n",
       "           0.1765, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.5843,  0.9765,\n",
       "           0.1686, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.5843,  0.9765,\n",
       "           0.1686, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.5843,  0.9765,\n",
       "           0.1686, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.6000,  1.0000,\n",
       "           0.1765, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.5843,  0.9765,\n",
       "           0.4902, -0.6863, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.5843,  0.9765,\n",
       "           0.9608, -0.2157, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6863,  0.9765,\n",
       "           0.9608, -0.2157, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.9922,\n",
       "           0.9765,  0.9765, -0.6157, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.9765,\n",
       "           0.9608,  0.9608, -0.6157, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.0196,\n",
       "           0.9608,  0.9608, -0.6157, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6000,\n",
       "           0.9608,  0.9608, -0.6157, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6000,\n",
       "           0.9765,  0.9765, -0.2941, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6000,\n",
       "           0.9608,  0.9608,  0.9608, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8431,\n",
       "           0.2549,  0.9608,  0.9608, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -0.2000,  0.9608,  0.9608, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000,  0.2000,  0.9765,  0.6000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000,  0.1843,  0.9608,  0.5843, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000,  0.1843,  0.9608,  0.5843, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000,  0.1843,  0.9608,  0.5843, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vi trenger et nettverk\n",
    "Alle lag i PyTorch arver fra `nn.Module`. Fra [dokumentasjonen](https://pytorch.org/docs/stable/generated/torch.nn.Module.html):\n",
    "\n",
    ">Base class for all neural network modules. \n",
    ">\n",
    ">Your models should also subclass this class.\n",
    ">\n",
    ">Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes:\n",
    "\n",
    "Trestrukturen som snakkes om er veldig nyttig. Endringer vi gjør på toppen av treet vil propageres ned til enkeltmodulene. Feks det å flytte parametrene over på en annen device.\n",
    "\n",
    "Vi husker det enkle lineære laget og sigmoid-funksjonen. De arver fra `nn.Module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.module.Module'>\n",
      "<class 'torch.nn.modules.module.Module'>\n"
     ]
    }
   ],
   "source": [
    "print(layer.__class__.__base__)\n",
    "print(sigmoid.__class__.__base__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer1): Linear(in_features=784, out_features=200, bias=True)\n",
       "  (layer2): Linear(in_features=200, out_features=42, bias=True)\n",
       "  (layer3): Linear(in_features=42, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features=28*28, out_features=200)\n",
    "        self.layer2 = nn.Linear(in_features=200, out_features=42)\n",
    "        self.layer3 = nn.Linear(in_features=42, out_features=10) # 10 digits to differentiate between\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1) # Softmax will be computed for each batch element separately \n",
    "\n",
    "    def logits(self, data):\n",
    "        flattened_data = torch.flatten(data, start_dim=1, end_dim=-1) # Flatten the tensor from shape (batch_size, 1, 28, 28) to shape (batch_size, 1 * 28 * 28)\n",
    "\n",
    "        out = self.layer1(flattened_data)\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        out = self.layer2(out)\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        out = self.layer3(out)\n",
    "        return out\n",
    "    \n",
    "    def forward(self, data):\n",
    "        logits = self.logits(data)\n",
    "        return self.softmax(logits)\n",
    "    \n",
    "model = Model() # Initialize model\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modellen vår implementerer to metoder. `logits` gir unnormaliserte verdier og vil brukes under trening. `forward` bruker `softmax` til å normalisere output fra `logits`, og tas i bruk under _inference_.\n",
    "\n",
    "Vi tester modellen på sifret vi visualiserte tidligere. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(data_sample.shape)\n",
    "test_input = data_sample[None, ...] # [None, ...] adds a new shape dimension in the front\n",
    "print(test_input.shape)\n",
    "test_input = test_input.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data_sample[None, ...]` lager en kopi av `data_sample` med en ny dimensjon lagt til.\n",
    "De fleste modulene i PyTorch forventer at input skal ha en batch-dimensjon, selv om batchen inneholder bare en instans (et bilde i dette tilfellet).\n",
    "\n",
    "Kodesnutten er veldig kryptisk. \n",
    "- PyTorch tolker indeksering med typen `None` som at en ny shape-dimensjon skal lages. \n",
    "- De etterfølgende `...` samler de resterende shape-dimensjonene. Dette er det samme som `data_sample[None, :, :, :]`.\n",
    "- `test_input` består av de nøyaktige samme elementene, men _organisert_ på en annen måte. \n",
    "\n",
    "En tilsvarende måte å skrive det på er `data_sample.unsqueeze(dim=X)`. Denne setter inn en ny (tom) dimensjon ved den spesifiserte dimensjonen. På samme måte kan man fjerne (tomme) dimensjoner med `data_sample.squeeze(dim=X)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1053, 0.1386, 0.0869, 0.1127, 0.1033, 0.1318, 0.0884, 0.0658, 0.0737,\n",
      "         0.0936]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "The untrained model predicts the digit to be 1\n"
     ]
    }
   ],
   "source": [
    "out = model.forward(test_input)\n",
    "print(out)\n",
    "print(f\"The untrained model predicts the digit to be {out.argmax()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trening\n",
    "Vi ser fra resultatene at modellen ikke er i stand til å avgjøre hvilket siffer inputten var. \n",
    "\n",
    "Vi har modellen og datasettet. Da er det to viktige ting som mangler for å kunne oppnå en fungerende modell. \n",
    "- **En loss-funksjon som definerer objectivet**\n",
    "    - Vi ønsker at modellen skal gi høyest sannsynlighet på det rette sifret.\n",
    "    \n",
    "- **En algoritme som utfører gradient descent, altså selve maskinlæringen**\n",
    "    - Denne algoritmen skal ta utgangspunkt i losset for å optimere parametrene.\n",
    "    - Man implementerer slike aldri selv, og finner dem heller gjennom `torch.optim`.\n",
    "\n",
    "#### Loss-funksjoner\n",
    "Loss-funksjoner sammenlikner en prediction og et target. Prediction er output fra modellen, og target er fasiten vi vet fra datasettet. \n",
    "Den enkleste er _Mean Squared Error (MSE)_, som kalkulerer gjennomsnittlig kvadrert avvik mellom tilsvarende elementer i hver tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(0.1724)\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(size=(3, 4, 5))\n",
    "b = torch.zeros(size=(3, 4, 5))\n",
    "loss = F.mse_loss(a, b)\n",
    "print(loss)\n",
    "\n",
    "a = torch.rand(size=(3, 4, 5))\n",
    "b = torch.rand(size=(3, 4, 5))\n",
    "loss = F.mse_loss(a, b)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient descent\n",
    "Helt fram til beregningen av et loss konstrueres det en såkalt _computational graph_. Denne kan propageres bakover for å beregne gradienter (derav det kjente navnet [backpropagation](https://simple.wikipedia.org/wiki/Backpropagation) som brukes i alle nevrale nettverk idag).\n",
    "- Fra matematikken vet vi at gradienter peker i retning hvor verdien øker mest i en flervariabel kurve. Beveger vi oss i motsatt retning vil verdien minske.\n",
    "- Learning rate (en skalar verdi) styrer hvor store stegene er. \n",
    "\n",
    "Figuren under viser loss-funksjonen kalkulert for forskjellige verdier av parametrene $\\theta_1$ og $\\theta_2$ til en modell. \n",
    "\n",
    "[<img src=\"https://zitaoshen.rbind.io/project/optimization/1-min-of-machine-learning-gradient-decent/featured_hubf6ae7b9a0510d717632b017746fdfc1_374655_720x0_resize_lanczos_2.png\">](https://zitaoshen.rbind.io/project/optimization/1-min-of-machine-learning-gradient-decent/)\n",
    "\n",
    "<!-- Oppdatering av vektene gjøres da slikt:\n",
    "\n",
    "$\\boldsymbol{w} \\leftarrow \\underbrace{\\alpha}_{\\text{learning rate}}$ -->\n",
    "\n",
    "Selv om konkrete regler finnes for beregning av gradientene til vektene, er det svært kronglete å gjøre manuelt. Derfor takker vi AI-gudene for bibliotek som PyTorch og Tensorflow som gjør denne prosessen så og si automatisk. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tilbake til treningen av en siffer-gjenkjenneren\n",
    "Til loss-funksjonen bruker vi `nn.CrossEntropyLoss`. Den sammenlikner to sannsynlighetsfordelinger. Matematikken bak er ikke så viktig.\n",
    "Til gradient descent bruker vi bruker Adam, som står for _Adaptive Moment Estimation_. Her er heller ikke matematikken viktig. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1875/1875 [00:07<00:00, 250.10batch/s]\n",
      "Epoch 1: 100%|██████████| 1875/1875 [00:07<00:00, 239.54batch/s]\n",
      "Epoch 2: 100%|██████████| 1875/1875 [00:07<00:00, 234.52batch/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm # Progress bar\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    with tqdm(train_loader, unit=\"batch\") as pbar:\n",
    "        pbar.set_description(f\"Epoch {epoch}\")\n",
    "        for i, (data, labels) in enumerate(pbar):\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pred = model.logits(data) # Query model for predictions\n",
    "            loss = loss_fn(pred, labels)\n",
    "            \n",
    "            loss.backward() # Propagate the computational graph and calculate gradients\n",
    "            optimizer.step() # Uses the calculated gradients on the registered parameters to perform an update\n",
    "            optimizer.zero_grad() # Remove the gradients\n",
    "\n",
    "            # pbar.set_postfix(loss=loss.cpu().item()) if i%40 == 0 else None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing av modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model on the test set is 0.9639999866485596\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=16)\n",
    "\n",
    "correct = 0\n",
    "for data, labels in test_loader:\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    pred = model.forward(data)\n",
    "    correct += torch.sum(pred.argmax(dim=1) == labels)\n",
    "accuracy = correct/len(test_dataset)\n",
    "\n",
    "print(f\"The accuracy of the model on the test set is {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.4524e-07, 9.9096e-01, 1.2377e-03, 1.0879e-03, 9.6513e-04, 1.0268e-04,\n",
      "         1.1486e-04, 2.3391e-03, 2.1955e-03, 9.9985e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "The trained model predicts the digit to be 1\n"
     ]
    }
   ],
   "source": [
    "out = model.forward(test_input)\n",
    "print(out)\n",
    "print(f\"The trained model predicts the digit to be {out.argmax()}\")\n",
    "# plt.bar(torch.linspace(0, 9, 10).numpy(), out[0].cpu().detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder\n",
    "\n",
    "For å komme litt inn i tankegangen om vektorrepresentasjoner av tekst (embeddings), ser vi på en arkitektur som kalles for AutoEncoder. \n",
    "\n",
    "Den består av to komponenter:\n",
    "- Encoder\n",
    "    - En serie med lineære lag som reduserer dimensjonaliteten.\n",
    "    - Ender opp med en vektor med bare 8 elementer (kontra 784 fra rådata)\n",
    "- Decoder\n",
    "    - En serie med lineære lag som rekonstruerer inputten fra den 8-dimensjonale vektorrepresentasjonen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=200, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=200, out_features=42, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=42, out_features=8, bias=True)\n",
       "    (5): Tanh()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=8, out_features=42, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=42, out_features=200, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=200, out_features=784, bias=True)\n",
       "    (5): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28, out_features=200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=200, out_features=42),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=42, out_features=8),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "             nn.Linear(in_features=8, out_features=42),\n",
    "             nn.Tanh(),\n",
    "             nn.Linear(in_features=42, out_features=200),\n",
    "             nn.Tanh(),\n",
    "             nn.Linear(200, 28*28),\n",
    "             nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def encode(self, data):\n",
    "        out = torch.flatten(data, start_dim=1, end_dim=-1)\n",
    "        out = self.encoder(out)\n",
    "        return out\n",
    "    \n",
    "    def decode(self, data):\n",
    "        out = self.decoder(data)\n",
    "        return out.reshape(-1, 1, 28, 28)\n",
    "\n",
    "    def forward(self, data):\n",
    "        out = self.encode(data)\n",
    "        return self.decode(out)\n",
    "    \n",
    "autoencoder = AutoEncoder()\n",
    "autoencoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1875/1875 [00:08<00:00, 221.23batch/s, loss=0.126]\n",
      "Epoch 1: 100%|██████████| 1875/1875 [00:08<00:00, 223.35batch/s, loss=0.0881]\n",
      "Epoch 2: 100%|██████████| 1875/1875 [00:08<00:00, 222.09batch/s, loss=0.101] \n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    with tqdm(train_loader, unit=\"batch\") as pbar:\n",
    "        pbar.set_description(f\"Epoch {epoch}\")\n",
    "        for i, (data, _) in enumerate(pbar): # no need for labels\n",
    "            data = data.to(device)\n",
    "            pred = autoencoder.forward(data) # Query model for predictions\n",
    "            loss = loss_fn(pred, data)\n",
    "            \n",
    "            loss.backward() # Propagate the computational graph and calculate gradients\n",
    "            optimizer.step() # Uses the calculated gradients on the registered parameters to perform an update\n",
    "            optimizer.zero_grad() # Remove the gradients\n",
    "\n",
    "            pbar.set_postfix(loss=loss.cpu().item()) if i%40 == 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9672, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-1.0000, device='cuda:0', grad_fn=<MinBackward1>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "rand_index = random.randint(0, len(data)-1)\n",
    "data_sample = data[rand_index]\n",
    "data_sample = autoencoder.forward(data_sample[None, ...])\n",
    "print(data_sample.max())\n",
    "print(data_sample.min())\n",
    "visualize(data_sample[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppvarming til NLP\n",
    "Bilder har en naturlig representasjon som vektorer/tensorer. Piksler som ligger ved siden av hverandre har relativt like verdier og man får fine overganger mellom. Tekst er strukturert på en litt mer rotete måte, og virker mer abstrakt.\n",
    "\n",
    "De fleste NLP-pipeliner begynner med en tokenizer, som oversetter deler av en setning til IDer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs: tensor([[  101,  2136, 19130,   102]])\n",
      "Tokens from IDs: ['[CLS]', 'team', 'camel', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"Team Camel\", return_tensors=\"pt\")\n",
    "print(f\"IDs: {inputs['input_ids']}\")\n",
    "print(f\"Tokens from IDs: {tokenizer.convert_ids_to_tokens(inputs['input_ids'].squeeze())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.5640948414802551,\n",
       "  'token': 2307,\n",
       "  'token_str': 'great',\n",
       "  'sequence': 'team kamel will achieve great things'},\n",
       " {'score': 0.26359036564826965,\n",
       "  'token': 2116,\n",
       "  'token_str': 'many',\n",
       "  'sequence': 'team kamel will achieve many things'},\n",
       " {'score': 0.0189247727394104,\n",
       "  'token': 2204,\n",
       "  'token_str': 'good',\n",
       "  'sequence': 'team kamel will achieve good things'},\n",
       " {'score': 0.013463899493217468,\n",
       "  'token': 2122,\n",
       "  'token_str': 'these',\n",
       "  'sequence': 'team kamel will achieve these things'},\n",
       " {'score': 0.011696144007146358,\n",
       "  'token': 2035,\n",
       "  'token_str': 'all',\n",
       "  'sequence': 'team kamel will achieve all things'}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
    "text = \"Team Kamel will achieve [MASK] things\"\n",
    "unmasker(inputs=text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
